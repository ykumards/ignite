


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>ignite.contrib.handlers &mdash; ignite master documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/ignite/index.htmlcontrib/handlers.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/css/ignite_theme.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="ignite.contrib.metrics" href="metrics.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/ignite/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="../concepts.html">Concepts</a>
          </li>

          <li>
            <a href="../quickstart.html">Quickstart</a>
          </li>

          <li>
            <a href="../examples.html">Examples</a>
          </li>

          <li>
            <a href="../faq.html">FAQ</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/ignite">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>


<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  0.3.0
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../concepts.html">Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">FAQ</a></li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../engine.html">ignite.engine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../handlers.html">ignite.handlers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../metrics.html">ignite.metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../exceptions.html">ignite.exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../utils.html">ignite.utils</a></li>
</ul>
<p class="caption"><span class="caption-text">Contrib Package Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="engines.html">ignite.contrib.engines</a></li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">ignite.contrib.metrics</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">ignite.contrib.handlers</a></li>
</ul>

            
          
        </div>
      </div>

      <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
        <span class="fa fa-book"> Other Versions</span>
        v: v0.3.0
        <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
        <dl>
            <dt>Tags</dt>
            <dd><a href="../v0.1.0/index.html">v0.1.0</a></dd>
            <dd><a href="../v0.1.1/contrib/handlers.html">v0.1.1</a></dd>
            <dd><a href="../v0.1.2/contrib/handlers.html">v0.1.2</a></dd>
            <dd><a href="../v0.2.0/contrib/handlers.html">v0.2.0</a></dd>
            <dd><a href="../v0.2.1/contrib/handlers.html">v0.2.1</a></dd>
            <dd><a href="../v0.3.0/contrib/handlers.html">v0.3.0</a></dd>
        </dl>
        <dl>
            <dt>Branches</dt>
            <dd><a href="../master/contrib/handlers.html">master</a></dd>
        </dl>
    </div>
</div>

    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>ignite.contrib.handlers</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/contrib/handlers.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="section" id="ignite-contrib-handlers">
<h1>ignite.contrib.handlers<a class="headerlink" href="#ignite-contrib-handlers" title="Permalink to this headline">¶</a></h1>
<p>Contribution module of handlers</p>
<div class="section" id="module-ignite.contrib.handlers.custom_events">
<span id="custom-events"></span><h2>custom_events<a class="headerlink" href="#module-ignite.contrib.handlers.custom_events" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="ignite.contrib.handlers.custom_events.CustomPeriodicEvent">
<em class="property">class </em><code class="descclassname">ignite.contrib.handlers.custom_events.</code><code class="descname">CustomPeriodicEvent</code><span class="sig-paren">(</span><em>n_iterations=None</em>, <em>n_epochs=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/custom_events.html#CustomPeriodicEvent"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.custom_events.CustomPeriodicEvent" title="Permalink to this definition">¶</a></dt>
<dd><p>Handler to define a custom periodic events as a number of elapsed iterations/epochs for an engine.</p>
<p>When custom periodic event is created and attached to an engine, the following events are fired:
1) K iterations is specified:
- <cite>Events.ITERATIONS_&lt;K&gt;_STARTED</cite>
- <cite>Events.ITERATIONS_&lt;K&gt;_COMPLETED</cite></p>
<p>1) K epochs is specified:
- <cite>Events.EPOCHS_&lt;K&gt;_STARTED</cite>
- <cite>Events.EPOCHS_&lt;K&gt;_COMPLETED</cite></p>
<p>Examples:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ignite.engine</span> <span class="kn">import</span> <span class="n">Engine</span><span class="p">,</span> <span class="n">Events</span>
<span class="kn">from</span> <span class="nn">ignite.contrib.handlers</span> <span class="kn">import</span> <span class="n">CustomPeriodicEvent</span>

<span class="c1"># Let&#39;s define an event every 1000 iterations</span>
<span class="n">cpe1</span> <span class="o">=</span> <span class="n">CustomPeriodicEvent</span><span class="p">(</span><span class="n">n_iterations</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">cpe1</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>

<span class="c1"># Let&#39;s define an event every 10 epochs</span>
<span class="n">cpe2</span> <span class="o">=</span> <span class="n">CustomPeriodicEvent</span><span class="p">(</span><span class="n">n_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">cpe2</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>

<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">cpe1</span><span class="o">.</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATIONS_1000_COMPLETED</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">on_every_1000_iterations</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
    <span class="c1"># run a computation after 1000 iterations</span>
    <span class="c1"># ...</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">iterations_1000</span><span class="p">)</span>

<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">cpe2</span><span class="o">.</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCHS_10_STARTED</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">on_every_10_epochs</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
    <span class="c1"># run a computation every 10 epochs</span>
    <span class="c1"># ...</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">epochs_10</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>n_iterations</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – number iterations of the custom periodic event</li>
<li><strong>n_epochs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – number iterations of the custom periodic event. Argument is optional, but only one,
either n_iterations or n_epochs should defined.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-ignite.contrib.handlers.param_scheduler">
<span id="param-scheduler"></span><h2>param_scheduler<a class="headerlink" href="#module-ignite.contrib.handlers.param_scheduler" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="ignite.contrib.handlers.param_scheduler.ConcatScheduler">
<em class="property">class </em><code class="descclassname">ignite.contrib.handlers.param_scheduler.</code><code class="descname">ConcatScheduler</code><span class="sig-paren">(</span><em>schedulers</em>, <em>durations</em>, <em>save_history=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ConcatScheduler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ConcatScheduler" title="Permalink to this definition">¶</a></dt>
<dd><p>Concat a list of parameter schedulers.</p>
<p>The <cite>ConcatScheduler</cite> goes through a list of schedulers given by <cite>schedulers</cite>. Duration of each
scheduler is defined by <cite>durations</cite> list of integers.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>schedulers</strong> (<em>list of ParamScheduler</em>) – list of parameter schedulers.</li>
<li><strong>durations</strong> (<em>list of int</em>) – list of number of events that lasts a parameter scheduler from schedulers.</li>
<li><strong>save_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – whether to log the parameter values to
<cite>engine.state.param_history</cite>, (default=False).</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Examples:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ignite.contrib.handlers.param_scheduler</span> <span class="kn">import</span> <span class="n">ConcatScheduler</span>
<span class="kn">from</span> <span class="nn">ignite.contrib.handlers.param_scheduler</span> <span class="kn">import</span> <span class="n">LinearCyclicalScheduler</span>
<span class="kn">from</span> <span class="nn">ignite.contrib.handlers.param_scheduler</span> <span class="kn">import</span> <span class="n">CosineAnnealingScheduler</span>

<span class="n">scheduler_1</span> <span class="o">=</span> <span class="n">LinearCyclicalScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">start_value</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
<span class="n">scheduler_2</span> <span class="o">=</span> <span class="n">CosineAnnealingScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">start_value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>

<span class="n">combined_scheduler</span> <span class="o">=</span> <span class="n">ConcatScheduler</span><span class="p">(</span><span class="n">schedulers</span><span class="o">=</span><span class="p">[</span><span class="n">scheduler_1</span><span class="p">,</span> <span class="n">scheduler_2</span><span class="p">],</span> <span class="n">durations</span><span class="o">=</span><span class="p">[</span><span class="mi">30</span><span class="p">,</span> <span class="p">])</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span> <span class="n">combined_scheduler</span><span class="p">)</span>
<span class="c1">#</span>
<span class="c1"># Sets the Learning rate linearly from 0.1 to 0.5 over 30 iterations. Then</span>
<span class="c1"># starts an annealing schedule from 0.5 to 0.01 over 60 iterations.</span>
<span class="c1"># The annealing cycles are repeated indefinitely.</span>
<span class="c1">#</span>
</pre></div>
</div>
<dl class="method">
<dt id="ignite.contrib.handlers.param_scheduler.ConcatScheduler.get_param">
<code class="descname">get_param</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ConcatScheduler.get_param"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ConcatScheduler.get_param" title="Permalink to this definition">¶</a></dt>
<dd><p>Method to get current optimizer’s parameter value</p>
</dd></dl>

<dl class="method">
<dt id="ignite.contrib.handlers.param_scheduler.ConcatScheduler.load_state_dict">
<code class="descname">load_state_dict</code><span class="sig-paren">(</span><em>state_dict</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ConcatScheduler.load_state_dict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ConcatScheduler.load_state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Copies parameters from <a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ConcatScheduler.state_dict" title="ignite.contrib.handlers.param_scheduler.ConcatScheduler.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> into this ConcatScheduler.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>state_dict</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – a dict containing parameters.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="classmethod">
<dt id="ignite.contrib.handlers.param_scheduler.ConcatScheduler.simulate_values">
<em class="property">classmethod </em><code class="descname">simulate_values</code><span class="sig-paren">(</span><em>num_events</em>, <em>schedulers</em>, <em>durations</em>, <em>param_names=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ConcatScheduler.simulate_values"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ConcatScheduler.simulate_values" title="Permalink to this definition">¶</a></dt>
<dd><p>Method to simulate scheduled values during num_events events.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>num_events</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – number of events during the simulation.</li>
<li><strong>schedulers</strong> (<em>list of ParamScheduler</em>) – list of parameter schedulers.</li>
<li><strong>durations</strong> (<em>list of int</em>) – list of number of events that lasts a parameter scheduler from schedulers.</li>
<li><strong>param_names</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em> or </em><em>tuple of str</em><em>, </em><em>optional</em>) – parameter name or list of parameter names to simulate values.
By default, the first scheduler’s parameter name is taken.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">list of [event_index, value_0, value_1, …], where values correspond to <cite>param_names</cite>.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="ignite.contrib.handlers.param_scheduler.ConcatScheduler.state_dict">
<code class="descname">state_dict</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ConcatScheduler.state_dict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ConcatScheduler.state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a dictionary containing a whole state of ConcatScheduler.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">a dictionary containing a whole state of ConcatScheduler</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.8)">dict</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="ignite.contrib.handlers.param_scheduler.CosineAnnealingScheduler">
<em class="property">class </em><code class="descclassname">ignite.contrib.handlers.param_scheduler.</code><code class="descname">CosineAnnealingScheduler</code><span class="sig-paren">(</span><em>optimizer</em>, <em>param_name</em>, <em>start_value</em>, <em>end_value</em>, <em>cycle_size</em>, <em>cycle_mult=1.0</em>, <em>start_value_mult=1.0</em>, <em>end_value_mult=1.0</em>, <em>save_history=False</em>, <em>param_group_index=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#CosineAnnealingScheduler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.CosineAnnealingScheduler" title="Permalink to this definition">¶</a></dt>
<dd><p>Anneals ‘start_value’ to ‘end_value’ over each cycle.</p>
<p>The annealing takes the form of the first half of a cosine
wave (as suggested in <a class="reference internal" href="#smith17" id="id1">[Smith17]</a>).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>optimizer</strong> (<cite>torch.optim.Optimizer</cite>) – optimizer</li>
<li><strong>param_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – name of optimizer’s parameter to update.</li>
<li><strong>start_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – value at start of cycle.</li>
<li><strong>end_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – value at the end of the cycle.</li>
<li><strong>cycle_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – length of cycle.</li>
<li><strong>cycle_mult</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – ratio by which to change the cycle_size
at the end of each cycle (default=1).</li>
<li><strong>start_value_mult</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – ratio by which to change the start value at the
end of each cycle (default=1.0).</li>
<li><strong>end_value_mult</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – ratio by which to change the end value at the
end of each cycle (default=1.0).</li>
<li><strong>save_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – whether to log the parameter values to
<cite>engine.state.param_history</cite>, (default=False).</li>
<li><strong>param_group_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – optimizer’s parameters group to use.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If the scheduler is bound to an ‘ITERATION_*’ event, ‘cycle_size’ should
usually be the number of batches in an epoch.</p>
</div>
<p>Examples:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ignite.contrib.handlers.param_scheduler</span> <span class="kn">import</span> <span class="n">CosineAnnealingScheduler</span>

<span class="n">scheduler</span> <span class="o">=</span> <span class="n">CosineAnnealingScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">)</span>
<span class="c1">#</span>
<span class="c1"># Anneals the learning rate from 1e-1 to 1e-3 over the course of 1 epoch.</span>
<span class="c1">#</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ignite.contrib.handlers.param_scheduler</span> <span class="kn">import</span> <span class="n">CosineAnnealingScheduler</span>
<span class="kn">from</span> <span class="nn">ignite.contrib.handlers.param_scheduler</span> <span class="kn">import</span> <span class="n">LinearCyclicalScheduler</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">),</span>
        <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">),</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">scheduler1</span> <span class="o">=</span> <span class="n">LinearCyclicalScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="mf">1e-7</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span> <span class="n">param_group_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span> <span class="n">scheduler1</span><span class="p">,</span> <span class="s2">&quot;lr (base)&quot;</span><span class="p">)</span>

<span class="n">scheduler2</span> <span class="o">=</span> <span class="n">CosineAnnealingScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span> <span class="n">param_group_index</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span> <span class="n">scheduler2</span><span class="p">,</span> <span class="s2">&quot;lr (fc)&quot;</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils citation" frame="void" id="smith17" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[Smith17]</a></td><td>Smith, Leslie N. “Cyclical learning rates for training neural networks.”
Applications of Computer Vision (WACV), 2017 IEEE Winter Conference on. IEEE, 2017</td></tr>
</tbody>
</table>
<dl class="method">
<dt id="ignite.contrib.handlers.param_scheduler.CosineAnnealingScheduler.get_param">
<code class="descname">get_param</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#CosineAnnealingScheduler.get_param"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.CosineAnnealingScheduler.get_param" title="Permalink to this definition">¶</a></dt>
<dd><p>Method to get current optimizer’s parameter value</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="ignite.contrib.handlers.param_scheduler.CyclicalScheduler">
<em class="property">class </em><code class="descclassname">ignite.contrib.handlers.param_scheduler.</code><code class="descname">CyclicalScheduler</code><span class="sig-paren">(</span><em>optimizer</em>, <em>param_name</em>, <em>start_value</em>, <em>end_value</em>, <em>cycle_size</em>, <em>cycle_mult=1.0</em>, <em>start_value_mult=1.0</em>, <em>end_value_mult=1.0</em>, <em>save_history=False</em>, <em>param_group_index=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#CyclicalScheduler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.CyclicalScheduler" title="Permalink to this definition">¶</a></dt>
<dd><p>An abstract class for updating an optimizer’s parameter value over a
cycle of some size.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>optimizer</strong> (<cite>torch.optim.Optimizer</cite>) – optimizer</li>
<li><strong>param_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – name of optimizer’s parameter to update.</li>
<li><strong>start_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – value at start of cycle.</li>
<li><strong>end_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – value at the middle of the cycle.</li>
<li><strong>cycle_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – length of cycle, value should be larger than 1.</li>
<li><strong>cycle_mult</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – ratio by which to change the cycle_size.
at the end of each cycle (default=1.0).</li>
<li><strong>start_value_mult</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – ratio by which to change the start value at the
end of each cycle (default=1.0).</li>
<li><strong>end_value_mult</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – ratio by which to change the end value at the
end of each cycle (default=1.0).</li>
<li><strong>save_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – whether to log the parameter values to
<cite>engine.state.param_history</cite>, (default=False).</li>
<li><strong>param_group_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – optimizer’s parameters group to use.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If the scheduler is bound to an ‘ITERATION_*’ event, ‘cycle_size’ should
usually be the number of batches in an epoch.</p>
</div>
</dd></dl>

<dl class="class">
<dt id="ignite.contrib.handlers.param_scheduler.LRScheduler">
<em class="property">class </em><code class="descclassname">ignite.contrib.handlers.param_scheduler.</code><code class="descname">LRScheduler</code><span class="sig-paren">(</span><em>lr_scheduler</em>, <em>save_history=False</em>, <em>**kwds</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#LRScheduler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.LRScheduler" title="Permalink to this definition">¶</a></dt>
<dd><p>A wrapper class to call <cite>torch.optim.lr_scheduler</cite> objects as <cite>ignite</cite> handlers.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>lr_scheduler</strong> (subclass of <cite>torch.optim.lr_scheduler._LRScheduler</cite>) – lr_scheduler object to wrap.</li>
<li><strong>save_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – whether to log the parameter values to
<cite>engine.state.param_history</cite>, (default=False).</li>
</ul>
</td>
</tr>
</tbody>
</table>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ignite.contrib.handlers.param_scheduler</span> <span class="kn">import</span> <span class="n">LRScheduler</span>
<span class="kn">from</span> <span class="nn">torch.optim.lr_scheduler</span> <span class="kn">import</span> <span class="n">StepLR</span>

<span class="n">step_scheduler</span> <span class="o">=</span> <span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">LRScheduler</span><span class="p">(</span><span class="n">step_scheduler</span><span class="p">)</span>

<span class="c1"># In this example, we assume to have installed PyTorch&gt;=1.1.0</span>
<span class="c1"># (with new `torch.optim.lr_scheduler` behaviour) and</span>
<span class="c1"># we attach scheduler to Events.ITERATION_COMPLETED</span>
<span class="c1"># instead of Events.ITERATION_STARTED to make sure to use</span>
<span class="c1"># the first lr value from the optimizer, otherwise it is will be skipped:</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="ignite.contrib.handlers.param_scheduler.LRScheduler.get_param">
<code class="descname">get_param</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#LRScheduler.get_param"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.LRScheduler.get_param" title="Permalink to this definition">¶</a></dt>
<dd><p>Method to get current optimizer’s parameter value</p>
</dd></dl>

<dl class="classmethod">
<dt id="ignite.contrib.handlers.param_scheduler.LRScheduler.simulate_values">
<em class="property">classmethod </em><code class="descname">simulate_values</code><span class="sig-paren">(</span><em>num_events</em>, <em>lr_scheduler</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#LRScheduler.simulate_values"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.LRScheduler.simulate_values" title="Permalink to this definition">¶</a></dt>
<dd><p>Method to simulate scheduled values during num_events events.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>num_events</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – number of events during the simulation.</li>
<li><strong>lr_scheduler</strong> (subclass of <cite>torch.optim.lr_scheduler._LRScheduler</cite>) – lr_scheduler object to wrap.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">[event_index, value]</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">list of pairs</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="ignite.contrib.handlers.param_scheduler.LinearCyclicalScheduler">
<em class="property">class </em><code class="descclassname">ignite.contrib.handlers.param_scheduler.</code><code class="descname">LinearCyclicalScheduler</code><span class="sig-paren">(</span><em>optimizer</em>, <em>param_name</em>, <em>start_value</em>, <em>end_value</em>, <em>cycle_size</em>, <em>cycle_mult=1.0</em>, <em>start_value_mult=1.0</em>, <em>end_value_mult=1.0</em>, <em>save_history=False</em>, <em>param_group_index=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#LinearCyclicalScheduler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.LinearCyclicalScheduler" title="Permalink to this definition">¶</a></dt>
<dd><p>Linearly adjusts param value to ‘end_value’ for a half-cycle, then linearly
adjusts it back to ‘start_value’ for a half-cycle.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>optimizer</strong> (<cite>torch.optim.Optimizer</cite>) – optimizer</li>
<li><strong>param_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – name of optimizer’s parameter to update.</li>
<li><strong>start_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – value at start of cycle.</li>
<li><strong>end_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – value at the middle of the cycle.</li>
<li><strong>cycle_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – length of cycle.</li>
<li><strong>cycle_mult</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – ratio by which to change the cycle_size
at the end of each cycle (default=1).</li>
<li><strong>start_value_mult</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – ratio by which to change the start value at the
end of each cycle (default=1.0).</li>
<li><strong>end_value_mult</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>, </em><em>optional</em>) – ratio by which to change the end value at the
end of each cycle (default=1.0).</li>
<li><strong>save_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – whether to log the parameter values to
<cite>engine.state.param_history</cite>, (default=False).</li>
<li><strong>param_group_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – optimizer’s parameters group to use.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If the scheduler is bound to an ‘ITERATION_*’ event, ‘cycle_size’ should
usually be the number of batches in an epoch.</p>
</div>
<p>Examples:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ignite.contrib.handlers.param_scheduler</span> <span class="kn">import</span> <span class="n">LinearCyclicalScheduler</span>

<span class="n">scheduler</span> <span class="o">=</span> <span class="n">LinearCyclicalScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">))</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">)</span>
<span class="c1">#</span>
<span class="c1"># Linearly increases the learning rate from 1e-3 to 1e-1 and back to 1e-3</span>
<span class="c1"># over the course of 1 epoch</span>
<span class="c1">#</span>
</pre></div>
</div>
<dl class="method">
<dt id="ignite.contrib.handlers.param_scheduler.LinearCyclicalScheduler.get_param">
<code class="descname">get_param</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#LinearCyclicalScheduler.get_param"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.LinearCyclicalScheduler.get_param" title="Permalink to this definition">¶</a></dt>
<dd><p>Method to get current optimizer’s parameter value</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="ignite.contrib.handlers.param_scheduler.ParamGroupScheduler">
<em class="property">class </em><code class="descclassname">ignite.contrib.handlers.param_scheduler.</code><code class="descname">ParamGroupScheduler</code><span class="sig-paren">(</span><em>schedulers</em>, <em>names</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ParamGroupScheduler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ParamGroupScheduler" title="Permalink to this definition">¶</a></dt>
<dd><p>Scheduler helper to group multiple schedulers into one.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>schedulers</strong> (<em>list/tuple of ParamScheduler</em>) – list/tuple of parameter schedulers.</li>
<li><strong>names</strong> (<em>list of str</em>) – list of names of schedulers.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">),</span>
        <span class="p">{</span><span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">),</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">scheduler1</span> <span class="o">=</span> <span class="n">LinearCyclicalScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="mf">1e-7</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span> <span class="n">param_group_index</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">scheduler2</span> <span class="o">=</span> <span class="n">CosineAnnealingScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="p">),</span> <span class="n">param_group_index</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">lr_schedulers</span> <span class="o">=</span> <span class="p">[</span><span class="n">scheduler1</span><span class="p">,</span> <span class="n">scheduler2</span><span class="p">]</span>
<span class="n">names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;lr (base)&quot;</span><span class="p">,</span> <span class="s2">&quot;lr (fc)&quot;</span><span class="p">]</span>

<span class="n">scheduler</span> <span class="o">=</span> <span class="n">ParamGroupScheduler</span><span class="p">(</span><span class="n">schedulers</span><span class="o">=</span><span class="n">lr_schedulers</span><span class="p">,</span> <span class="n">names</span><span class="o">=</span><span class="n">names</span><span class="p">)</span>
<span class="c1"># Attach single scheduler to the trainer</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="ignite.contrib.handlers.param_scheduler.ParamGroupScheduler.load_state_dict">
<code class="descname">load_state_dict</code><span class="sig-paren">(</span><em>state_dict</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ParamGroupScheduler.load_state_dict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ParamGroupScheduler.load_state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Copies parameters from <a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ParamGroupScheduler.state_dict" title="ignite.contrib.handlers.param_scheduler.ParamGroupScheduler.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> into this ParamScheduler.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>state_dict</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – a dict containing parameters.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="ignite.contrib.handlers.param_scheduler.ParamGroupScheduler.state_dict">
<code class="descname">state_dict</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ParamGroupScheduler.state_dict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ParamGroupScheduler.state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a dictionary containing a whole state of ParamGroupScheduler.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">a dictionary containing a whole state of ParamGroupScheduler</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.8)">dict</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="ignite.contrib.handlers.param_scheduler.ParamScheduler">
<em class="property">class </em><code class="descclassname">ignite.contrib.handlers.param_scheduler.</code><code class="descname">ParamScheduler</code><span class="sig-paren">(</span><em>optimizer</em>, <em>param_name</em>, <em>save_history=False</em>, <em>param_group_index=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ParamScheduler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler" title="Permalink to this definition">¶</a></dt>
<dd><p>An abstract class for updating an optimizer’s parameter value during
training.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>optimizer</strong> (<cite>torch.optim.Optimizer</cite>) – optimizer</li>
<li><strong>param_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – name of optimizer’s parameter to update.</li>
<li><strong>save_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – whether to log the parameter values to
<cite>engine.state.param_history</cite>, (default=False).</li>
<li><strong>param_group_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – optimizer’s parameters group to use</li>
</ul>
</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Parameter scheduler works independently of the internal state of the attached optimizer.
More precisely, whatever the state of the optimizer (newly created or used by another scheduler) the scheduler
sets defined absolute values.</p>
</div>
<dl class="method">
<dt id="ignite.contrib.handlers.param_scheduler.ParamScheduler.get_param">
<code class="descname">get_param</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ParamScheduler.get_param"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler.get_param" title="Permalink to this definition">¶</a></dt>
<dd><p>Method to get current optimizer’s parameter value</p>
</dd></dl>

<dl class="method">
<dt id="ignite.contrib.handlers.param_scheduler.ParamScheduler.load_state_dict">
<code class="descname">load_state_dict</code><span class="sig-paren">(</span><em>state_dict</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ParamScheduler.load_state_dict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler.load_state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Copies parameters from <a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler.state_dict" title="ignite.contrib.handlers.param_scheduler.ParamScheduler.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> into this ParamScheduler.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>state_dict</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.8)"><em>dict</em></a>) – a dict containing parameters.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="classmethod">
<dt id="ignite.contrib.handlers.param_scheduler.ParamScheduler.plot_values">
<em class="property">classmethod </em><code class="descname">plot_values</code><span class="sig-paren">(</span><em>num_events</em>, <em>**scheduler_kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ParamScheduler.plot_values"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler.plot_values" title="Permalink to this definition">¶</a></dt>
<dd><p>Method to plot simulated scheduled values during <cite>num_events</cite> events.</p>
<p>This class requires <a class="reference external" href="https://matplotlib.org/">matplotlib package</a> to be installed:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip install matplotlib
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>num_events</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – number of events during the simulation.</li>
<li><strong>**scheduler_kwargs</strong> – parameter scheduler configuration kwargs.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">matplotlib.lines.Line2D</p>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">LinearCyclicalScheduler</span><span class="o">.</span><span class="n">plot_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                                    <span class="n">start_value</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

<dl class="classmethod">
<dt id="ignite.contrib.handlers.param_scheduler.ParamScheduler.simulate_values">
<em class="property">classmethod </em><code class="descname">simulate_values</code><span class="sig-paren">(</span><em>num_events</em>, <em>**scheduler_kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ParamScheduler.simulate_values"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler.simulate_values" title="Permalink to this definition">¶</a></dt>
<dd><p>Method to simulate scheduled values during <cite>num_events</cite> events.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>num_events</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – number of events during the simulation.</li>
<li><strong>**scheduler_kwargs</strong> – parameter scheduler configuration kwargs.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">[event_index, value]</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">list of pairs</p>
</td>
</tr>
</tbody>
</table>
<p>Examples:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">lr_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">LinearCyclicalScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                                                             <span class="n">start_value</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
                                                             <span class="n">cycle_size</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="ignite.contrib.handlers.param_scheduler.ParamScheduler.state_dict">
<code class="descname">state_dict</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#ParamScheduler.state_dict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.ParamScheduler.state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a dictionary containing a whole state of ParamScheduler.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">a dictionary containing a whole state of ParamScheduler</td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.8)">dict</a></td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="ignite.contrib.handlers.param_scheduler.PiecewiseLinear">
<em class="property">class </em><code class="descclassname">ignite.contrib.handlers.param_scheduler.</code><code class="descname">PiecewiseLinear</code><span class="sig-paren">(</span><em>optimizer</em>, <em>param_name</em>, <em>milestones_values</em>, <em>save_history=False</em>, <em>param_group_index=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#PiecewiseLinear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.PiecewiseLinear" title="Permalink to this definition">¶</a></dt>
<dd><p>Piecewise linear parameter scheduler</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>optimizer</strong> (<cite>torch.optim.Optimizer</cite>) – optimizer.</li>
<li><strong>param_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – name of optimizer’s parameter to update.</li>
<li><strong>milestones_values</strong> (<em>list of tuples</em><em> (</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a><em>)</em>) – list of tuples (event index, parameter value)
represents milestones and parameter. Milestones should be increasing integers.</li>
<li><strong>save_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – whether to log the parameter values to
<cite>engine.state.param_history</cite>, (default=False).</li>
<li><strong>param_group_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – optimizer’s parameters group to use.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">piecewise linear scheduler</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.PiecewiseLinear" title="ignite.contrib.handlers.param_scheduler.PiecewiseLinear">PiecewiseLinear</a></p>
</td>
</tr>
</tbody>
</table>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">scheduler</span> <span class="o">=</span> <span class="n">PiecewiseLinear</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span>
                            <span class="n">milestones_values</span><span class="o">=</span><span class="p">[(</span><span class="mi">10</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mf">0.45</span><span class="p">),</span> <span class="p">(</span><span class="mi">21</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">),</span> <span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span> <span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)])</span>
<span class="c1"># Attach to the trainer</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">)</span>
<span class="c1">#</span>
<span class="c1"># Sets the learning rate to 0.5 over the first 10 iterations, then decreases linearly from 0.5 to 0.45 between</span>
<span class="c1"># 10th and 20th iterations. Next there is a jump to 0.3 at the 21st iteration and LR decreases linearly</span>
<span class="c1"># from 0.3 to 0.1 between 21st and 30th iterations and remains 0.1 until the end of the iterations.</span>
<span class="c1">#</span>
</pre></div>
</div>
<dl class="method">
<dt id="ignite.contrib.handlers.param_scheduler.PiecewiseLinear.get_param">
<code class="descname">get_param</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#PiecewiseLinear.get_param"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.PiecewiseLinear.get_param" title="Permalink to this definition">¶</a></dt>
<dd><p>Method to get current optimizer’s parameter value</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="ignite.contrib.handlers.param_scheduler.create_lr_scheduler_with_warmup">
<code class="descclassname">ignite.contrib.handlers.param_scheduler.</code><code class="descname">create_lr_scheduler_with_warmup</code><span class="sig-paren">(</span><em>lr_scheduler</em>, <em>warmup_start_value</em>, <em>warmup_end_value</em>, <em>warmup_duration</em>, <em>save_history=False</em>, <em>output_simulated_values=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/param_scheduler.html#create_lr_scheduler_with_warmup"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.param_scheduler.create_lr_scheduler_with_warmup" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper method to create a learning rate scheduler with a linear warm-up.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>lr_scheduler</strong> (ParamScheduler or subclass of <cite>torch.optim.lr_scheduler._LRScheduler</cite>) – learning rate scheduler
after the warm-up.</li>
<li><strong>warmup_start_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – learning rate start value of the warm-up phase.</li>
<li><strong>warmup_end_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – learning rate end value of the warm-up phase.</li>
<li><strong>warmup_duration</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – warm-up phase duration, number of events.</li>
<li><strong>save_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – whether to log the parameter values to
<cite>engine.state.param_history</cite>, (default=False).</li>
<li><strong>output_simulated_values</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.8)"><em>list</em></a><em>, </em><em>optional</em>) – optional output of simulated learning rate values.
If output_simulated_values is a list of None, e.g. <cite>[None] * 100</cite>, after the execution it will be filled
by 100 simulated learning rate values.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">learning rate scheduler with linear warm-up.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference internal" href="#ignite.contrib.handlers.param_scheduler.ConcatScheduler" title="ignite.contrib.handlers.param_scheduler.ConcatScheduler">ConcatScheduler</a></p>
</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">If the first learning rate value provided by <cite>lr_scheduler</cite> is different from <cite>warmup_end_value</cite>, an additional
event is added after the warm-up phase such that the warm-up ends with <cite>warmup_end_value</cite> value and then
<cite>lr_scheduler</cite> provides its learning rate values as normally.</p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">torch_lr_scheduler</span> <span class="o">=</span> <span class="n">ExponentialLR</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.98</span><span class="p">)</span>
<span class="n">lr_values</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">create_lr_scheduler_with_warmup</span><span class="p">(</span><span class="n">torch_lr_scheduler</span><span class="p">,</span>
                                            <span class="n">warmup_start_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                                            <span class="n">warmup_end_value</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                                            <span class="n">warmup_duration</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                                            <span class="n">output_simulated_values</span><span class="o">=</span><span class="n">lr_values</span><span class="p">)</span>
<span class="n">lr_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">lr_values</span><span class="p">)</span>
<span class="c1"># Plot simulated values</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>

<span class="c1"># Attach to the trainer</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">add_event_handler</span><span class="p">(</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="tensorboard-logger">
<h2>tensorboard_logger<a class="headerlink" href="#tensorboard-logger" title="Permalink to this headline">¶</a></h2>
<p>See <a class="reference external" href="https://github.com/pytorch/ignite/blob/master/examples/contrib/mnist/mnist_with_tensorboard_logger.py">tensorboardX mnist example</a>
and <a class="reference external" href="https://github.com/pytorch/ignite/tree/master/examples/notebooks">CycleGAN and EfficientNet notebooks</a> for detailed usage.</p>
<span class="target" id="module-ignite.contrib.handlers.tensorboard_logger"></span><dl class="class">
<dt id="ignite.contrib.handlers.tensorboard_logger.TensorboardLogger">
<em class="property">class </em><code class="descclassname">ignite.contrib.handlers.tensorboard_logger.</code><code class="descname">TensorboardLogger</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/tensorboard_logger.html#TensorboardLogger"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.tensorboard_logger.TensorboardLogger" title="Permalink to this definition">¶</a></dt>
<dd><p>TensorBoard handler to log metrics, model/optimizer parameters, gradients during the training and validation.</p>
<p>By default, this class favors <a class="reference external" href="https://github.com/lanpa/tensorboardX">tensorboardX</a> package if installed:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip install tensorboardX
</pre></div>
</div>
<p>otherwise, it falls back to using PyTorch’s SummaryWriter (&gt;=v1.2.0).</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>*args</strong> – Positional arguments accepted from <code class="xref py py-class docutils literal notranslate"><span class="pre">SummaryWriter</span></code>.</li>
<li><strong>**kwargs</strong> – Keyword arguments accepted from <code class="xref py py-class docutils literal notranslate"><span class="pre">SummaryWriter</span></code>, for example,
<cite>log_dir</cite> to setup path to the directory where to log.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ignite.contrib.handlers.tensorboard_logger</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">tb_logger</span> <span class="o">=</span> <span class="n">TensorboardLogger</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;experiments/tb_logs&quot;</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log training loss at each iteration</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span> <span class="n">output_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">loss</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">}),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the training dataset and log NLL, Accuracy metrics after each epoch</span>
<span class="c1"># We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch</span>
<span class="c1"># of the `trainer` instead of `train_evaluator`.</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">train_evaluator</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span>
                                           <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                           <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch of the</span>
<span class="c1"># `trainer` instead of `evaluator`.</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">evaluator</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
                                           <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                           <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log optimizer&#39;s parameters, e.g. learning rate at each iteration</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">OptimizerParamsHandler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">WeightsScalarHandler</span><span class="p">(</span><span class="n">model</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights as a histogram after each epoch</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">WeightsHistHandler</span><span class="p">(</span><span class="n">model</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s gradients norm after each iteration</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">GradsScalarHandler</span><span class="p">(</span><span class="n">model</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s gradients as a histogram after each epoch</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">GradsHistHandler</span><span class="p">(</span><span class="n">model</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>

<span class="c1"># We need to close the logger with we are done</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p>It is also possible to use the logger as context manager:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ignite.contrib.handlers.tensorboard_logger</span> <span class="kn">import</span> <span class="o">*</span>

<span class="k">with</span> <span class="n">TensorboardLogger</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;experiments/tb_logs&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">tb_logger</span><span class="p">:</span>

    <span class="n">trainer</span> <span class="o">=</span> <span class="n">Engine</span><span class="p">(</span><span class="n">update_fn</span><span class="p">)</span>
    <span class="c1"># Attach the logger to the trainer to log training loss at each iteration</span>
    <span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                     <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span>
                                               <span class="n">output_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">loss</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">}),</span>
                     <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="ignite.contrib.handlers.tensorboard_logger.TensorboardLogger.attach">
<code class="descname">attach</code><span class="sig-paren">(</span><em>engine</em>, <em>log_handler</em>, <em>event_name</em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.tensorboard_logger.TensorboardLogger.attach" title="Permalink to this definition">¶</a></dt>
<dd><p>Attach the logger to the engine and execute <cite>log_handler</cite> function at <cite>event_name</cite> events.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.Engine" title="ignite.engine.Engine"><em>Engine</em></a>) – engine object.</li>
<li><strong>log_handler</strong> (<em>callable</em>) – a logging handler to execute</li>
<li><strong>event_name</strong> – event to attach the logging handler to. Valid events are from <a class="reference internal" href="../engine.html#ignite.engine.Events" title="ignite.engine.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a>
or any <cite>event_name</cite> added by <a class="reference internal" href="../engine.html#ignite.engine.Engine.register_events" title="ignite.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="ignite.contrib.handlers.tensorboard_logger.OptimizerParamsHandler">
<em class="property">class </em><code class="descclassname">ignite.contrib.handlers.tensorboard_logger.</code><code class="descname">OptimizerParamsHandler</code><span class="sig-paren">(</span><em>optimizer</em>, <em>param_name='lr'</em>, <em>tag=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/tensorboard_logger.html#OptimizerParamsHandler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.tensorboard_logger.OptimizerParamsHandler" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper handler to log optimizer parameters</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ignite.contrib.handlers.tensorboard_logger</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">tb_logger</span> <span class="o">=</span> <span class="n">TensorboardLogger</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;experiments/tb_logs&quot;</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log optimizer&#39;s parameters, e.g. learning rate at each iteration</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">OptimizerParamsHandler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>optimizer</strong> (<em>torch.optim.Optimizer</em>) – torch optimizer which parameters to log</li>
<li><strong>param_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – parameter name</li>
<li><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – common title for all produced plots. For example, ‘generator’</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="ignite.contrib.handlers.tensorboard_logger.OutputHandler">
<em class="property">class </em><code class="descclassname">ignite.contrib.handlers.tensorboard_logger.</code><code class="descname">OutputHandler</code><span class="sig-paren">(</span><em>tag</em>, <em>metric_names=None</em>, <em>output_transform=None</em>, <em>another_engine=None</em>, <em>global_step_transform=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/tensorboard_logger.html#OutputHandler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.tensorboard_logger.OutputHandler" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper handler to log engine’s output and/or metrics</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ignite.contrib.handlers.tensorboard_logger</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">tb_logger</span> <span class="o">=</span> <span class="n">TensorboardLogger</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;experiments/tb_logs&quot;</span><span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch</span>
<span class="c1"># of the `trainer`:</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">evaluator</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
                                           <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                           <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<p>Example with CustomPeriodicEvent, where model is evaluated every 500 iterations:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ignite.contrib.handlers</span> <span class="kn">import</span> <span class="n">CustomPeriodicEvent</span>

<span class="n">cpe</span> <span class="o">=</span> <span class="n">CustomPeriodicEvent</span><span class="p">(</span><span class="n">n_iterations</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">cpe</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>

<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">cpe</span><span class="o">.</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATIONS_500_COMPLETED</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
    <span class="n">evaluator</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">validation_set</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">ignite.contrib.handlers.tensorboard_logger</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">tb_logger</span> <span class="o">=</span> <span class="n">TensorboardLogger</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;experiments/tb_logs&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">global_step_transform</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">iteration</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># every 500 iterations. Since evaluator engine does not have CustomPeriodicEvent attached to it, we</span>
<span class="c1"># provide a global_step_transform to return the trainer.state.iteration for the global_step, each time</span>
<span class="c1"># evaluator metrics are plotted on Tensorboard.</span>

<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">evaluator</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
                                           <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                           <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_transform</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – common title for all produced plots. For example, ‘training’</li>
<li><strong>metric_names</strong> (<em>list of str</em><em>, </em><em>optional</em>) – list of metric names to plot or a string “all” to plot all available
metrics.</li>
<li><strong>output_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – output transform function to prepare <cite>engine.state.output</cite> as a number.
For example, <cite>output_transform = lambda output: output</cite>
This function can also return a dictionary, e.g <cite>{‘loss’: loss1, `another_loss</cite>: loss2}` to label the plot
with corresponding keys.</li>
<li><strong>another_engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.Engine" title="ignite.engine.Engine"><em>Engine</em></a>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">global_step_transform</span></code>). Another engine to use to provide the
value of event. Typically, user can provide
the trainer if this handler is attached to an evaluator and thus it logs proper trainer’s
epoch/iteration value.</li>
<li><strong>global_step_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – global step transform function to output a desired global step.
Input of the function is <cite>(engine, event_name)</cite>. Output of function should be an integer.
Default is None, global_step based on attached engine. If provided,
uses function output as global_step. To setup global step from another engine, please use
<a class="reference internal" href="#ignite.contrib.handlers.tensorboard_logger.global_step_from_engine" title="ignite.contrib.handlers.tensorboard_logger.global_step_from_engine"><code class="xref py py-meth docutils literal notranslate"><span class="pre">global_step_from_engine()</span></code></a>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Example of <cite>global_step_transform</cite>:</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">global_step_transform</span><span class="p">(</span><span class="n">engine</span><span class="p">,</span> <span class="n">event_name</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">get_event_attrib_value</span><span class="p">(</span><span class="n">event_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="class">
<dt id="ignite.contrib.handlers.tensorboard_logger.WeightsScalarHandler">
<em class="property">class </em><code class="descclassname">ignite.contrib.handlers.tensorboard_logger.</code><code class="descname">WeightsScalarHandler</code><span class="sig-paren">(</span><em>model</em>, <em>reduction=&lt;function norm&gt;</em>, <em>tag=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/tensorboard_logger.html#WeightsScalarHandler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.tensorboard_logger.WeightsScalarHandler" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper handler to log model’s weights as scalars.
Handler iterates over named parameters of the model, applies reduction function to each parameter
produce a scalar and then logs the scalar.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ignite.contrib.handlers.tensorboard_logger</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">tb_logger</span> <span class="o">=</span> <span class="n">TensorboardLogger</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;experiments/tb_logs&quot;</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">WeightsScalarHandler</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>model</strong> (<em>torch.nn.Module</em>) – model to log weights</li>
<li><strong>reduction</strong> (<em>callable</em>) – function to reduce parameters into scalar</li>
<li><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – common title for all produced plots. For example, ‘generator’</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="ignite.contrib.handlers.tensorboard_logger.WeightsHistHandler">
<em class="property">class </em><code class="descclassname">ignite.contrib.handlers.tensorboard_logger.</code><code class="descname">WeightsHistHandler</code><span class="sig-paren">(</span><em>model</em>, <em>tag=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/tensorboard_logger.html#WeightsHistHandler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.tensorboard_logger.WeightsHistHandler" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper handler to log model’s weights as histograms.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ignite.contrib.handlers.tensorboard_logger</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">tb_logger</span> <span class="o">=</span> <span class="n">TensorboardLogger</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;experiments/tb_logs&quot;</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">WeightsHistHandler</span><span class="p">(</span><span class="n">model</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>model</strong> (<em>torch.nn.Module</em>) – model to log weights</li>
<li><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – common title for all produced plots. For example, ‘generator’</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="ignite.contrib.handlers.tensorboard_logger.GradsScalarHandler">
<em class="property">class </em><code class="descclassname">ignite.contrib.handlers.tensorboard_logger.</code><code class="descname">GradsScalarHandler</code><span class="sig-paren">(</span><em>model</em>, <em>reduction=&lt;function norm&gt;</em>, <em>tag=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/tensorboard_logger.html#GradsScalarHandler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.tensorboard_logger.GradsScalarHandler" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper handler to log model’s gradients as scalars.
Handler iterates over the gradients of named parameters of the model, applies reduction function to each parameter
produce a scalar and then logs the scalar.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ignite.contrib.handlers.tensorboard_logger</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">tb_logger</span> <span class="o">=</span> <span class="n">TensorboardLogger</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;experiments/tb_logs&quot;</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">GradsScalarHandler</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>model</strong> (<em>torch.nn.Module</em>) – model to log weights</li>
<li><strong>reduction</strong> (<em>callable</em>) – function to reduce parameters into scalar</li>
<li><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – common title for all produced plots. For example, ‘generator’</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="ignite.contrib.handlers.tensorboard_logger.GradsHistHandler">
<em class="property">class </em><code class="descclassname">ignite.contrib.handlers.tensorboard_logger.</code><code class="descname">GradsHistHandler</code><span class="sig-paren">(</span><em>model</em>, <em>tag=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/tensorboard_logger.html#GradsHistHandler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.tensorboard_logger.GradsHistHandler" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper handler to log model’s gradients as histograms.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ignite.contrib.handlers.tensorboard_logger</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">tb_logger</span> <span class="o">=</span> <span class="n">TensorboardLogger</span><span class="p">(</span><span class="n">log_dir</span><span class="o">=</span><span class="s2">&quot;experiments/tb_logs&quot;</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">tb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">GradsHistHandler</span><span class="p">(</span><span class="n">model</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>model</strong> (<em>torch.nn.Module</em>) – model to log weights</li>
<li><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – common title for all produced plots. For example, ‘generator’</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="ignite.contrib.handlers.tensorboard_logger.global_step_from_engine">
<code class="descclassname">ignite.contrib.handlers.tensorboard_logger.</code><code class="descname">global_step_from_engine</code><span class="sig-paren">(</span><em>engine</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/handlers.html#global_step_from_engine"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.tensorboard_logger.global_step_from_engine" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper method to setup <cite>global_step_transform</cite> function using another engine.
This can be helpful for logging trainer epoch/iteration while output handler is attached to an evaluator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.Engine" title="ignite.engine.Engine"><em>Engine</em></a>) – engine which state is used to provide the global step</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">global step</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="visdom-logger">
<h2>visdom_logger<a class="headerlink" href="#visdom-logger" title="Permalink to this headline">¶</a></h2>
<p>See <a class="reference external" href="https://github.com/pytorch/ignite/blob/master/examples/contrib/mnist/mnist_with_visdom_logger.py">visdom mnist example</a>
for detailed usage.</p>
<span class="target" id="module-ignite.contrib.handlers.visdom_logger"></span><dl class="class">
<dt id="ignite.contrib.handlers.visdom_logger.VisdomLogger">
<em class="property">class </em><code class="descclassname">ignite.contrib.handlers.visdom_logger.</code><code class="descname">VisdomLogger</code><span class="sig-paren">(</span><em>server=None</em>, <em>port=None</em>, <em>num_workers=1</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/visdom_logger.html#VisdomLogger"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.VisdomLogger" title="Permalink to this definition">¶</a></dt>
<dd><p>VisdomLogger handler to log metrics, model/optimizer parameters, gradients during the training and validation.</p>
<p>This class requires <a class="reference external" href="https://github.com/facebookresearch/visdom/">visdom</a> package to be installed:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip install git+https://github.com/facebookresearch/visdom.git
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>server</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – visdom server URL. It can be also specified by environment variable <cite>VISDOM_SERVER_URL</cite></li>
<li><strong>port</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – visdom server’s port. It can be also specified by environment variable <cite>VISDOM_PORT</cite></li>
<li><strong>num_workers</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em>, </em><em>optional</em>) – number of workers to use in <cite>concurrent.futures.ThreadPoolExecutor</cite> to post data to
visdom server. Default, <cite>num_workers=1</cite>. If <cite>num_workers=0</cite> and logger uses the main thread. If using
Python 2.7 and <cite>num_workers&gt;0</cite> the package <cite>futures</cite> should be installed: <cite>pip install futures</cite></li>
<li><strong>**kwargs</strong> – kwargs to pass into
<a class="reference external" href="https://github.com/facebookresearch/visdom#visdom-arguments-python-only">visdom.Visdom</a>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">We can also specify username/password using environment variables: VISDOM_USERNAME, VISDOM_PASSWORD</p>
</div>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">Frequent logging, e.g. when logger is attached to <cite>Events.ITERATION_COMPLETED</cite>, can slow down the run if the
main thread is used to send the data to visdom server (<cite>num_workers=0</cite>). To avoid this situation we can either
log less frequently or set <cite>num_workers=1</cite>.</p>
</div>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ignite.contrib.handlers.visdom_logger</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">vd_logger</span> <span class="o">=</span> <span class="n">VisdomLogger</span><span class="p">()</span>

<span class="c1"># Attach the logger to the trainer to log training loss at each iteration</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span> <span class="n">output_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">loss</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">}),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the training dataset and log NLL, Accuracy metrics after each epoch</span>
<span class="c1"># We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch</span>
<span class="c1"># of the `trainer` instead of `train_evaluator`:</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">train_evaluator</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span>
                                           <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                           <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch of</span>
<span class="c1"># the `trainer` instead of `evaluator`:</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">evaluator</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
                                           <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                           <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log optimizer&#39;s parameters, e.g. learning rate at each iteration</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">optimizer_params_handler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">weights_scalar_handler</span><span class="p">(</span><span class="n">model</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s gradients norm after each iteration</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">grads_scalar_handler</span><span class="p">(</span><span class="n">model</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>

<span class="c1"># We need to close the logger with we are done</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
<p>It is also possible to use the logger as context manager:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ignite.contrib.handlers.visdom_logger</span> <span class="kn">import</span> <span class="o">*</span>

<span class="k">with</span> <span class="n">VisdomLogger</span><span class="p">()</span> <span class="k">as</span> <span class="n">vd_logger</span><span class="p">:</span>

    <span class="n">trainer</span> <span class="o">=</span> <span class="n">Engine</span><span class="p">(</span><span class="n">update_fn</span><span class="p">)</span>
    <span class="c1"># Attach the logger to the trainer to log training loss at each iteration</span>
    <span class="n">vd_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                     <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span>
                                               <span class="n">output_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">loss</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">}),</span>
                     <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="ignite.contrib.handlers.visdom_logger.VisdomLogger.attach">
<code class="descname">attach</code><span class="sig-paren">(</span><em>engine</em>, <em>log_handler</em>, <em>event_name</em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.VisdomLogger.attach" title="Permalink to this definition">¶</a></dt>
<dd><p>Attach the logger to the engine and execute <cite>log_handler</cite> function at <cite>event_name</cite> events.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.Engine" title="ignite.engine.Engine"><em>Engine</em></a>) – engine object.</li>
<li><strong>log_handler</strong> (<em>callable</em>) – a logging handler to execute</li>
<li><strong>event_name</strong> – event to attach the logging handler to. Valid events are from <a class="reference internal" href="../engine.html#ignite.engine.Events" title="ignite.engine.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a>
or any <cite>event_name</cite> added by <a class="reference internal" href="../engine.html#ignite.engine.Engine.register_events" title="ignite.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="ignite.contrib.handlers.visdom_logger.OptimizerParamsHandler">
<em class="property">class </em><code class="descclassname">ignite.contrib.handlers.visdom_logger.</code><code class="descname">OptimizerParamsHandler</code><span class="sig-paren">(</span><em>optimizer</em>, <em>param_name='lr'</em>, <em>tag=None</em>, <em>show_legend=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/visdom_logger.html#OptimizerParamsHandler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.OptimizerParamsHandler" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper handler to log optimizer parameters</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ignite.contrib.handlers.visdom_logger</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">vb_logger</span> <span class="o">=</span> <span class="n">VisdomLogger</span><span class="p">()</span>

<span class="c1"># Attach the logger to the trainer to log optimizer&#39;s parameters, e.g. learning rate at each iteration</span>
<span class="n">vb_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">OptimizerParamsHandler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>optimizer</strong> (<em>torch.optim.Optimizer</em>) – torch optimizer which parameters to log</li>
<li><strong>param_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – parameter name</li>
<li><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – common title for all produced plots. For example, ‘generator’</li>
<li><strong>show_legend</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – flag to show legend in the window</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="ignite.contrib.handlers.visdom_logger.OptimizerParamsHandler.add_scalar">
<code class="descname">add_scalar</code><span class="sig-paren">(</span><em>logger</em>, <em>k</em>, <em>v</em>, <em>event_name</em>, <em>global_step</em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.OptimizerParamsHandler.add_scalar" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper method to log a scalar with VisdomLogger.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>logger</strong> (<a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.VisdomLogger" title="ignite.contrib.handlers.visdom_logger.VisdomLogger"><em>VisdomLogger</em></a>) – visdom logger</li>
<li><strong>k</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – scalar name which is used to set window title and y-axis label</li>
<li><strong>v</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – scalar value, y-axis value</li>
<li><strong>event_name</strong> – Event name which is used to setup x-axis label. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.Events" title="ignite.engine.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.Engine.register_events" title="ignite.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</li>
<li><strong>global_step</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – global step, x-axis value</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="ignite.contrib.handlers.visdom_logger.OutputHandler">
<em class="property">class </em><code class="descclassname">ignite.contrib.handlers.visdom_logger.</code><code class="descname">OutputHandler</code><span class="sig-paren">(</span><em>tag</em>, <em>metric_names=None</em>, <em>output_transform=None</em>, <em>another_engine=None</em>, <em>global_step_transform=None</em>, <em>show_legend=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/visdom_logger.html#OutputHandler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.OutputHandler" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper handler to log engine’s output and/or metrics</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ignite.contrib.handlers.visdom_logger</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">vd_logger</span> <span class="o">=</span> <span class="n">VisdomLogger</span><span class="p">()</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch of</span>
<span class="c1"># the `trainer`:</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">evaluator</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
                                           <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                           <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<p>Example with CustomPeriodicEvent, where model is evaluated every 500 iterations:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ignite.contrib.handlers</span> <span class="kn">import</span> <span class="n">CustomPeriodicEvent</span>

<span class="n">cpe</span> <span class="o">=</span> <span class="n">CustomPeriodicEvent</span><span class="p">(</span><span class="n">n_iterations</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">cpe</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>

<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">cpe</span><span class="o">.</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATIONS_500_COMPLETED</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
    <span class="n">evaluator</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">validation_set</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">ignite.contrib.handlers.visdom_logger</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">vd_logger</span> <span class="o">=</span> <span class="n">VisdomLogger</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">global_step_transform</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">iteration</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># every 500 iterations. Since evaluator engine does not have CustomPeriodicEvent attached to it, we</span>
<span class="c1"># provide a global_step_transform to return the trainer.state.iteration for the global_step, each time</span>
<span class="c1"># evaluator metrics are plotted on Visdom.</span>


<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">evaluator</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
                                           <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                           <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_transform</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – common title for all produced plots. For example, ‘training’</li>
<li><strong>metric_names</strong> (<em>list of str</em><em>, </em><em>optional</em>) – list of metric names to plot or a string “all” to plot all available
metrics.</li>
<li><strong>output_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – output transform function to prepare <cite>engine.state.output</cite> as a number.
For example, <cite>output_transform = lambda output: output</cite>
This function can also return a dictionary, e.g <cite>{‘loss’: loss1, `another_loss</cite>: loss2}` to label the plot
with corresponding keys.</li>
<li><strong>another_engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.Engine" title="ignite.engine.Engine"><em>Engine</em></a>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">global_step_transform</span></code>). Another engine to use to provide the
value of event. Typically, user can provide
the trainer if this handler is attached to an evaluator and thus it logs proper trainer’s
epoch/iteration value.</li>
<li><strong>global_step_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – global step transform function to output a desired global step.
Input of the function is <cite>(engine, event_name)</cite>. Output of function should be an integer.
Default is None, global_step based on attached engine. If provided,
uses function output as global_step. To setup global step from another engine, please use
<a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.global_step_from_engine" title="ignite.contrib.handlers.visdom_logger.global_step_from_engine"><code class="xref py py-meth docutils literal notranslate"><span class="pre">global_step_from_engine()</span></code></a>.</li>
<li><strong>show_legend</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – flag to show legend in the window</li>
</ul>
</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Example of <cite>global_step_transform</cite>:</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">global_step_transform</span><span class="p">(</span><span class="n">engine</span><span class="p">,</span> <span class="n">event_name</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">get_event_attrib_value</span><span class="p">(</span><span class="n">event_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
<dl class="method">
<dt id="ignite.contrib.handlers.visdom_logger.OutputHandler.add_scalar">
<code class="descname">add_scalar</code><span class="sig-paren">(</span><em>logger</em>, <em>k</em>, <em>v</em>, <em>event_name</em>, <em>global_step</em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.OutputHandler.add_scalar" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper method to log a scalar with VisdomLogger.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>logger</strong> (<a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.VisdomLogger" title="ignite.contrib.handlers.visdom_logger.VisdomLogger"><em>VisdomLogger</em></a>) – visdom logger</li>
<li><strong>k</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – scalar name which is used to set window title and y-axis label</li>
<li><strong>v</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – scalar value, y-axis value</li>
<li><strong>event_name</strong> – Event name which is used to setup x-axis label. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.Events" title="ignite.engine.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.Engine.register_events" title="ignite.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</li>
<li><strong>global_step</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – global step, x-axis value</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="ignite.contrib.handlers.visdom_logger.WeightsScalarHandler">
<em class="property">class </em><code class="descclassname">ignite.contrib.handlers.visdom_logger.</code><code class="descname">WeightsScalarHandler</code><span class="sig-paren">(</span><em>model</em>, <em>reduction=&lt;function norm&gt;</em>, <em>tag=None</em>, <em>show_legend=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/visdom_logger.html#WeightsScalarHandler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.WeightsScalarHandler" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper handler to log model’s weights as scalars.
Handler iterates over named parameters of the model, applies reduction function to each parameter
produce a scalar and then logs the scalar.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ignite.contrib.handlers.visdom_logger</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">vd_logger</span> <span class="o">=</span> <span class="n">VisdomLogger</span><span class="p">()</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">WeightsScalarHandler</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>model</strong> (<em>torch.nn.Module</em>) – model to log weights</li>
<li><strong>reduction</strong> (<em>callable</em>) – function to reduce parameters into scalar</li>
<li><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – common title for all produced plots. For example, ‘generator’</li>
<li><strong>show_legend</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – flag to show legend in the window</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="ignite.contrib.handlers.visdom_logger.WeightsScalarHandler.add_scalar">
<code class="descname">add_scalar</code><span class="sig-paren">(</span><em>logger</em>, <em>k</em>, <em>v</em>, <em>event_name</em>, <em>global_step</em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.WeightsScalarHandler.add_scalar" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper method to log a scalar with VisdomLogger.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>logger</strong> (<a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.VisdomLogger" title="ignite.contrib.handlers.visdom_logger.VisdomLogger"><em>VisdomLogger</em></a>) – visdom logger</li>
<li><strong>k</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – scalar name which is used to set window title and y-axis label</li>
<li><strong>v</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – scalar value, y-axis value</li>
<li><strong>event_name</strong> – Event name which is used to setup x-axis label. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.Events" title="ignite.engine.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.Engine.register_events" title="ignite.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</li>
<li><strong>global_step</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – global step, x-axis value</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="ignite.contrib.handlers.visdom_logger.GradsScalarHandler">
<em class="property">class </em><code class="descclassname">ignite.contrib.handlers.visdom_logger.</code><code class="descname">GradsScalarHandler</code><span class="sig-paren">(</span><em>model</em>, <em>reduction=&lt;function norm&gt;</em>, <em>tag=None</em>, <em>show_legend=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/visdom_logger.html#GradsScalarHandler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.GradsScalarHandler" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper handler to log model’s gradients as scalars.
Handler iterates over the gradients of named parameters of the model, applies reduction function to each parameter
produce a scalar and then logs the scalar.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ignite.contrib.handlers.visdom_logger</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">vd_logger</span> <span class="o">=</span> <span class="n">VisdomLogger</span><span class="p">()</span>

<span class="c1"># Attach the logger to the trainer to log model&#39;s weights norm after each iteration</span>
<span class="n">vd_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                 <span class="n">log_handler</span><span class="o">=</span><span class="n">GradsScalarHandler</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">),</span>
                 <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>model</strong> (<em>torch.nn.Module</em>) – model to log weights</li>
<li><strong>reduction</strong> (<em>callable</em>) – function to reduce parameters into scalar</li>
<li><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – common title for all produced plots. For example, ‘generator’</li>
<li><strong>show_legend</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – flag to show legend in the window</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="ignite.contrib.handlers.visdom_logger.GradsScalarHandler.add_scalar">
<code class="descname">add_scalar</code><span class="sig-paren">(</span><em>logger</em>, <em>k</em>, <em>v</em>, <em>event_name</em>, <em>global_step</em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.GradsScalarHandler.add_scalar" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper method to log a scalar with VisdomLogger.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>logger</strong> (<a class="reference internal" href="#ignite.contrib.handlers.visdom_logger.VisdomLogger" title="ignite.contrib.handlers.visdom_logger.VisdomLogger"><em>VisdomLogger</em></a>) – visdom logger</li>
<li><strong>k</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – scalar name which is used to set window title and y-axis label</li>
<li><strong>v</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – scalar value, y-axis value</li>
<li><strong>event_name</strong> – Event name which is used to setup x-axis label. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.Events" title="ignite.engine.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a> or any <cite>event_name</cite> added by
<a class="reference internal" href="../engine.html#ignite.engine.Engine.register_events" title="ignite.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</li>
<li><strong>global_step</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – global step, x-axis value</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="ignite.contrib.handlers.visdom_logger.global_step_from_engine">
<code class="descclassname">ignite.contrib.handlers.visdom_logger.</code><code class="descname">global_step_from_engine</code><span class="sig-paren">(</span><em>engine</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/handlers.html#global_step_from_engine"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.visdom_logger.global_step_from_engine" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper method to setup <cite>global_step_transform</cite> function using another engine.
This can be helpful for logging trainer epoch/iteration while output handler is attached to an evaluator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.Engine" title="ignite.engine.Engine"><em>Engine</em></a>) – engine which state is used to provide the global step</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">global step</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-ignite.contrib.handlers.mlflow_logger">
<span id="mlflow-logger"></span><h2>mlflow_logger<a class="headerlink" href="#module-ignite.contrib.handlers.mlflow_logger" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="ignite.contrib.handlers.mlflow_logger.MLflowLogger">
<em class="property">class </em><code class="descclassname">ignite.contrib.handlers.mlflow_logger.</code><code class="descname">MLflowLogger</code><span class="sig-paren">(</span><em>tracking_uri=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/mlflow_logger.html#MLflowLogger"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.mlflow_logger.MLflowLogger" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://mlflow.org">MLflow</a> tracking client handler to log parameters and metrics during the training
and validation.</p>
<p>This class requires <a class="reference external" href="https://github.com/mlflow/mlflow/">mlflow package</a> to be installed:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip install mlflow
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>tracking_uri</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – MLflow tracking uri. See MLflow docs for more details</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ignite.contrib.handlers.mlflow_logger</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">mlflow_logger</span> <span class="o">=</span> <span class="n">MLflowLogger</span><span class="p">()</span>

<span class="c1"># Log experiment parameters:</span>
<span class="n">mlflow_logger</span><span class="o">.</span><span class="n">log_params</span><span class="p">(</span><span class="o">**</span><span class="p">{</span>
    <span class="s2">&quot;seed&quot;</span><span class="p">:</span> <span class="n">seed</span><span class="p">,</span>
    <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="n">batch_size</span><span class="p">,</span>
    <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>

    <span class="s2">&quot;pytorch version&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
    <span class="s2">&quot;ignite version&quot;</span><span class="p">:</span> <span class="n">ignite</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
    <span class="s2">&quot;cuda version&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">version</span><span class="o">.</span><span class="n">cuda</span><span class="p">,</span>
    <span class="s2">&quot;device name&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="p">})</span>

<span class="c1"># Attach the logger to the evaluator on the training dataset and log NLL, Accuracy metrics after each epoch</span>
<span class="c1"># We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch</span>
<span class="c1"># of the `trainer` instead of `train_evaluator`.</span>
<span class="n">mlflow_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">train_evaluator</span><span class="p">,</span>
                     <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span>
                                               <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                               <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)),</span>
                     <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch of the</span>
<span class="c1"># `trainer` instead of `evaluator`.</span>
<span class="n">mlflow_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">evaluator</span><span class="p">,</span>
                     <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
                                               <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                               <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)),</span>
                     <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="ignite.contrib.handlers.mlflow_logger.MLflowLogger.attach">
<code class="descname">attach</code><span class="sig-paren">(</span><em>engine</em>, <em>log_handler</em>, <em>event_name</em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.mlflow_logger.MLflowLogger.attach" title="Permalink to this definition">¶</a></dt>
<dd><p>Attach the logger to the engine and execute <cite>log_handler</cite> function at <cite>event_name</cite> events.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.Engine" title="ignite.engine.Engine"><em>Engine</em></a>) – engine object.</li>
<li><strong>log_handler</strong> (<em>callable</em>) – a logging handler to execute</li>
<li><strong>event_name</strong> – event to attach the logging handler to. Valid events are from <a class="reference internal" href="../engine.html#ignite.engine.Events" title="ignite.engine.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a>
or any <cite>event_name</cite> added by <a class="reference internal" href="../engine.html#ignite.engine.Engine.register_events" title="ignite.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="ignite.contrib.handlers.mlflow_logger.OutputHandler">
<em class="property">class </em><code class="descclassname">ignite.contrib.handlers.mlflow_logger.</code><code class="descname">OutputHandler</code><span class="sig-paren">(</span><em>tag</em>, <em>metric_names=None</em>, <em>output_transform=None</em>, <em>another_engine=None</em>, <em>global_step_transform=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/mlflow_logger.html#OutputHandler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.mlflow_logger.OutputHandler" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper handler to log engine’s output and/or metrics.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ignite.contrib.handlers.mlflow_logger</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">mlflow_logger</span> <span class="o">=</span> <span class="n">MLflowLogger</span><span class="p">()</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch</span>
<span class="c1"># of the `trainer`:</span>
<span class="n">mlflow_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">evaluator</span><span class="p">,</span>
                     <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
                                               <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                               <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)),</span>
                     <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<p>Example with CustomPeriodicEvent, where model is evaluated every 500 iterations:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ignite.contrib.handlers</span> <span class="kn">import</span> <span class="n">CustomPeriodicEvent</span>

<span class="n">cpe</span> <span class="o">=</span> <span class="n">CustomPeriodicEvent</span><span class="p">(</span><span class="n">n_iterations</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">cpe</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>

<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">cpe</span><span class="o">.</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATIONS_500_COMPLETED</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
    <span class="n">evaluator</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">validation_set</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">ignite.contrib.handlers.mlflow_logger</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">mlflow_logger</span> <span class="o">=</span> <span class="n">MLflowLogger</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">global_step_transform</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">iteration</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># every 500 iterations. Since evaluator engine does not have CustomPeriodicEvent attached to it, we</span>
<span class="c1"># provide a global_step_transform to return the trainer.state.iteration for the global_step, each time</span>
<span class="c1"># evaluator metrics are plotted on MLflow.</span>

<span class="n">mlflow_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">evaluator</span><span class="p">,</span>
                    <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
                                              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                              <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_transform</span><span class="p">),</span>
                    <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – common title for all produced plots. For example, ‘training’</li>
<li><strong>metric_names</strong> (<em>list of str</em><em>, </em><em>optional</em>) – list of metric names to plot or a string “all” to plot all available
metrics.</li>
<li><strong>output_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – output transform function to prepare <cite>engine.state.output</cite> as a number.
For example, <cite>output_transform = lambda output: output</cite>
This function can also return a dictionary, e.g <cite>{‘loss’: loss1, `another_loss</cite>: loss2}` to label the plot
with corresponding keys.</li>
<li><strong>another_engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.Engine" title="ignite.engine.Engine"><em>Engine</em></a>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">global_step_transform</span></code>). Another engine to use to provide the
value of event. Typically, user can provide
the trainer if this handler is attached to an evaluator and thus it logs proper trainer’s
epoch/iteration value.</li>
<li><strong>global_step_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – global step transform function to output a desired global step.
Input of the function is <cite>(engine, event_name)</cite>. Output of function should be an integer.
Default is None, global_step based on attached engine. If provided,
uses function output as global_step. To setup global step from another engine, please use
<a class="reference internal" href="#ignite.contrib.handlers.mlflow_logger.global_step_from_engine" title="ignite.contrib.handlers.mlflow_logger.global_step_from_engine"><code class="xref py py-meth docutils literal notranslate"><span class="pre">global_step_from_engine()</span></code></a>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Example of <cite>global_step_transform</cite>:</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">global_step_transform</span><span class="p">(</span><span class="n">engine</span><span class="p">,</span> <span class="n">event_name</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">get_event_attrib_value</span><span class="p">(</span><span class="n">event_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="class">
<dt id="ignite.contrib.handlers.mlflow_logger.OptimizerParamsHandler">
<em class="property">class </em><code class="descclassname">ignite.contrib.handlers.mlflow_logger.</code><code class="descname">OptimizerParamsHandler</code><span class="sig-paren">(</span><em>optimizer</em>, <em>param_name='lr'</em>, <em>tag=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/mlflow_logger.html#OptimizerParamsHandler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.mlflow_logger.OptimizerParamsHandler" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper handler to log optimizer parameters</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ignite.contrib.handlers.mlflow_logger</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">mlflow_logger</span> <span class="o">=</span> <span class="n">MLflowLogger</span><span class="p">()</span>
<span class="c1"># Optionally, user can specify tracking_uri with corresponds to MLFLOW_TRACKING_URI</span>
<span class="c1"># mlflow_logger = MLflowLogger(tracking_uri=&quot;uri&quot;)</span>

<span class="c1"># Attach the logger to the trainer to log optimizer&#39;s parameters, e.g. learning rate at each iteration</span>
<span class="n">mlflow_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                     <span class="n">log_handler</span><span class="o">=</span><span class="n">OptimizerParamsHandler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">),</span>
                     <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>optimizer</strong> (<em>torch.optim.Optimizer</em>) – torch optimizer which parameters to log</li>
<li><strong>param_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – parameter name</li>
<li><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – common title for all produced plots. For example, ‘generator’</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="ignite.contrib.handlers.mlflow_logger.global_step_from_engine">
<code class="descclassname">ignite.contrib.handlers.mlflow_logger.</code><code class="descname">global_step_from_engine</code><span class="sig-paren">(</span><em>engine</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/handlers.html#global_step_from_engine"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.mlflow_logger.global_step_from_engine" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper method to setup <cite>global_step_transform</cite> function using another engine.
This can be helpful for logging trainer epoch/iteration while output handler is attached to an evaluator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.Engine" title="ignite.engine.Engine"><em>Engine</em></a>) – engine which state is used to provide the global step</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">global step</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="module-ignite.contrib.handlers.tqdm_logger">
<span id="tqdm-logger"></span><h2>tqdm_logger<a class="headerlink" href="#module-ignite.contrib.handlers.tqdm_logger" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="ignite.contrib.handlers.tqdm_logger.ProgressBar">
<em class="property">class </em><code class="descclassname">ignite.contrib.handlers.tqdm_logger.</code><code class="descname">ProgressBar</code><span class="sig-paren">(</span><em>persist=False</em>, <em>bar_format='{desc}[{n_fmt}/{total_fmt}] {percentage:3.0f}%|{bar}{postfix} [{elapsed}&lt;{remaining}]'</em>, <em>**tqdm_kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/tqdm_logger.html#ProgressBar"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.tqdm_logger.ProgressBar" title="Permalink to this definition">¶</a></dt>
<dd><p>TQDM progress bar handler to log training progress and computed metrics.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>persist</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.8)"><em>bool</em></a><em>, </em><em>optional</em>) – set to <code class="docutils literal notranslate"><span class="pre">True</span></code> to persist the progress bar after completion (default = <code class="docutils literal notranslate"><span class="pre">False</span></code>)</li>
<li><strong>bar_format</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – Specify a custom bar string formatting. May impact performance.
[default: ‘{desc}[{n_fmt}/{total_fmt}] {percentage:3.0f}%|{bar}{postfix} [{elapsed}&lt;{remaining}]’].
Set to <code class="docutils literal notranslate"><span class="pre">None</span></code> to use <code class="docutils literal notranslate"><span class="pre">tqdm</span></code> default bar formatting: ‘{l_bar}{bar}{r_bar}’, where
l_bar=’{desc}: {percentage:3.0f}%|’ and
r_bar=’| {n_fmt}/{total_fmt} [{elapsed}&lt;{remaining}, {rate_fmt}{postfix}]’. For more details on the
formatting, see <a class="reference external" href="https://tqdm.github.io/docs/tqdm/">tqdm docs</a>.</li>
<li><strong>**tqdm_kwargs</strong> – kwargs passed to tqdm progress bar.
By default, progress bar description displays “Epoch [5/10]” where 5 is the current epoch and 10 is the
number of epochs. If tqdm_kwargs defines <cite>desc</cite>, e.g. “Predictions”, than the description is
“Predictions [5/10]” if number of epochs is more than one otherwise it is simply “Predictions”.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<p>Simple progress bar</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">create_supervised_trainer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>

<span class="n">pbar</span> <span class="o">=</span> <span class="n">ProgressBar</span><span class="p">()</span>
<span class="n">pbar</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>

<span class="c1"># Progress bar will looks like</span>
<span class="c1"># Epoch [2/50]: [64/128]  50%|█████      [06:17&lt;12:34]</span>
</pre></div>
</div>
<p>Log output to a file instead of stderr (tqdm’s default output)</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">create_supervised_trainer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>

<span class="n">log_file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;output.log&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span>
<span class="n">pbar</span> <span class="o">=</span> <span class="n">ProgressBar</span><span class="p">(</span><span class="n">file</span><span class="o">=</span><span class="n">log_file</span><span class="p">)</span>
<span class="n">pbar</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>
</pre></div>
</div>
<p>Attach metrics that already have been computed at <a class="reference internal" href="../engine.html#ignite.engine.Events.ITERATION_COMPLETED" title="ignite.engine.Events.ITERATION_COMPLETED"><code class="xref py py-attr docutils literal notranslate"><span class="pre">ITERATION_COMPLETED</span></code></a>
(such as <a class="reference internal" href="../metrics.html#ignite.metrics.RunningAverage" title="ignite.metrics.RunningAverage"><code class="xref py py-class docutils literal notranslate"><span class="pre">RunningAverage</span></code></a>)</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">create_supervised_trainer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>

<span class="n">RunningAverage</span><span class="p">(</span><span class="n">output_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="s1">&#39;loss&#39;</span><span class="p">)</span>

<span class="n">pbar</span> <span class="o">=</span> <span class="n">ProgressBar</span><span class="p">()</span>
<span class="n">pbar</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span>

<span class="c1"># Progress bar will looks like</span>
<span class="c1"># Epoch [2/50]: [64/128]  50%|█████      , loss=0.123 [06:17&lt;12:34]</span>
</pre></div>
</div>
<p>Directly attach the engine’s output</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">create_supervised_trainer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>

<span class="n">pbar</span> <span class="o">=</span> <span class="n">ProgressBar</span><span class="p">()</span>
<span class="n">pbar</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">output_transform</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">x</span><span class="p">})</span>

<span class="c1"># Progress bar will looks like</span>
<span class="c1"># Epoch [2/50]: [64/128]  50%|█████      , loss=0.123 [06:17&lt;12:34]</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">When adding attaching the progress bar to an engine, it is recommend that you replace
every print operation in the engine’s handlers triggered every iteration with
<code class="docutils literal notranslate"><span class="pre">pbar.log_message</span></code> to guarantee the correct format of the stdout.</p>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">When using inside jupyter notebook, <cite>ProgressBar</cite> automatically uses <cite>tqdm_notebook</cite>. For correct rendering,
please install <a class="reference external" href="https://ipywidgets.readthedocs.io/en/stable/user_install.html#installation">ipywidgets</a>.
Due to <a class="reference external" href="https://github.com/tqdm/tqdm/issues/594">tqdm notebook bugs</a>, bar format may be needed to be set
to an empty string value.</p>
</div>
<dl class="method">
<dt id="ignite.contrib.handlers.tqdm_logger.ProgressBar.attach">
<code class="descname">attach</code><span class="sig-paren">(</span><em>engine</em>, <em>metric_names=None</em>, <em>output_transform=None</em>, <em>event_name=&lt;Events.ITERATION_COMPLETED: 'iteration_completed'&gt;</em>, <em>closing_event_name=&lt;Events.EPOCH_COMPLETED: 'epoch_completed'&gt;</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/tqdm_logger.html#ProgressBar.attach"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.tqdm_logger.ProgressBar.attach" title="Permalink to this definition">¶</a></dt>
<dd><p>Attaches the progress bar to an engine object.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.Engine" title="ignite.engine.Engine"><em>Engine</em></a>) – engine object.</li>
<li><strong>metric_names</strong> (<em>list of str</em><em>, </em><em>optional</em>) – list of metric names to plot or a string “all” to plot all available
metrics.</li>
<li><strong>output_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – a function to select what you want to print from the engine’s
output. This function may return either a dictionary with entries in the format of <code class="docutils literal notranslate"><span class="pre">{name:</span> <span class="pre">value}</span></code>,
or a single scalar, which will be displayed with the default name <cite>output</cite>.</li>
<li><strong>event_name</strong> – event’s name on which the progress bar advances. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.Events" title="ignite.engine.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a>.</li>
<li><strong>closing_event_name</strong> – event’s name on which the progress bar is closed. Valid events are from
<a class="reference internal" href="../engine.html#ignite.engine.Events" title="ignite.engine.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p>Note: accepted output value types are numbers, 0d and 1d torch tensors and strings</p>
</dd></dl>

<dl class="method">
<dt id="ignite.contrib.handlers.tqdm_logger.ProgressBar.log_message">
<code class="descname">log_message</code><span class="sig-paren">(</span><em>message</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/tqdm_logger.html#ProgressBar.log_message"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.tqdm_logger.ProgressBar.log_message" title="Permalink to this definition">¶</a></dt>
<dd><p>Logs a message, preserving the progress bar correct output format.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>message</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – string you wish to log.</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-ignite.contrib.handlers.polyaxon_logger">
<span id="polyaxon-logger"></span><h2>polyaxon_logger<a class="headerlink" href="#module-ignite.contrib.handlers.polyaxon_logger" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="ignite.contrib.handlers.polyaxon_logger.PolyaxonLogger">
<em class="property">class </em><code class="descclassname">ignite.contrib.handlers.polyaxon_logger.</code><code class="descname">PolyaxonLogger</code><a class="reference internal" href="../_modules/ignite/contrib/handlers/polyaxon_logger.html#PolyaxonLogger"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.polyaxon_logger.PolyaxonLogger" title="Permalink to this definition">¶</a></dt>
<dd><p><a class="reference external" href="https://polyaxon.com/">Polyaxon</a> tracking client handler to log parameters and metrics during the training
and validation.</p>
<p>This class requires <a class="reference external" href="https://github.com/polyaxon/polyaxon-client/">polyaxon-client</a> package to be installed:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip install polyaxon-client
</pre></div>
</div>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ignite.contrib.handlers.polyaxon_logger</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">plx_logger</span> <span class="o">=</span> <span class="n">PolyaxonLogger</span><span class="p">()</span>

<span class="c1"># Log experiment parameters:</span>
<span class="n">plx_logger</span><span class="o">.</span><span class="n">log_params</span><span class="p">(</span><span class="o">**</span><span class="p">{</span>
    <span class="s2">&quot;seed&quot;</span><span class="p">:</span> <span class="n">seed</span><span class="p">,</span>
    <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="n">batch_size</span><span class="p">,</span>
    <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>

    <span class="s2">&quot;pytorch version&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
    <span class="s2">&quot;ignite version&quot;</span><span class="p">:</span> <span class="n">ignite</span><span class="o">.</span><span class="n">__version__</span><span class="p">,</span>
    <span class="s2">&quot;cuda version&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">version</span><span class="o">.</span><span class="n">cuda</span><span class="p">,</span>
    <span class="s2">&quot;device name&quot;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="p">})</span>

<span class="c1"># Attach the logger to the evaluator on the training dataset and log NLL, Accuracy metrics after each epoch</span>
<span class="c1"># We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch</span>
<span class="c1"># of the `trainer` instead of `train_evaluator`.</span>
<span class="n">plx_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">train_evaluator</span><span class="p">,</span>
                  <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;training&quot;</span><span class="p">,</span>
                                            <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                            <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)),</span>
                  <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch of the</span>
<span class="c1"># `trainer` instead of `evaluator`.</span>
<span class="n">plx_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">evaluator</span><span class="p">,</span>
                  <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
                                            <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                            <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)),</span>
                  <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="ignite.contrib.handlers.polyaxon_logger.PolyaxonLogger.attach">
<code class="descname">attach</code><span class="sig-paren">(</span><em>engine</em>, <em>log_handler</em>, <em>event_name</em><span class="sig-paren">)</span><a class="headerlink" href="#ignite.contrib.handlers.polyaxon_logger.PolyaxonLogger.attach" title="Permalink to this definition">¶</a></dt>
<dd><p>Attach the logger to the engine and execute <cite>log_handler</cite> function at <cite>event_name</cite> events.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.Engine" title="ignite.engine.Engine"><em>Engine</em></a>) – engine object.</li>
<li><strong>log_handler</strong> (<em>callable</em>) – a logging handler to execute</li>
<li><strong>event_name</strong> – event to attach the logging handler to. Valid events are from <a class="reference internal" href="../engine.html#ignite.engine.Events" title="ignite.engine.Events"><code class="xref py py-class docutils literal notranslate"><span class="pre">Events</span></code></a>
or any <cite>event_name</cite> added by <a class="reference internal" href="../engine.html#ignite.engine.Engine.register_events" title="ignite.engine.Engine.register_events"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_events()</span></code></a>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="ignite.contrib.handlers.polyaxon_logger.OutputHandler">
<em class="property">class </em><code class="descclassname">ignite.contrib.handlers.polyaxon_logger.</code><code class="descname">OutputHandler</code><span class="sig-paren">(</span><em>tag</em>, <em>metric_names=None</em>, <em>output_transform=None</em>, <em>another_engine=None</em>, <em>global_step_transform=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/polyaxon_logger.html#OutputHandler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.polyaxon_logger.OutputHandler" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper handler to log engine’s output and/or metrics.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ignite.contrib.handlers.polyaxon_logger</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">plx_logger</span> <span class="o">=</span> <span class="n">PolyaxonLogger</span><span class="p">()</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># each epoch. We setup `global_step_transform=global_step_from_engine(trainer)` to take the epoch</span>
<span class="c1"># of the `trainer`:</span>
<span class="n">plx_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">evaluator</span><span class="p">,</span>
                  <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
                                            <span class="n">metric_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                            <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_from_engine</span><span class="p">(</span><span class="n">trainer</span><span class="p">)),</span>
                  <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<p>Example with CustomPeriodicEvent, where model is evaluated every 500 iterations:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ignite.contrib.handlers</span> <span class="kn">import</span> <span class="n">CustomPeriodicEvent</span>

<span class="n">cpe</span> <span class="o">=</span> <span class="n">CustomPeriodicEvent</span><span class="p">(</span><span class="n">n_iterations</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">cpe</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>

<span class="nd">@trainer</span><span class="o">.</span><span class="n">on</span><span class="p">(</span><span class="n">cpe</span><span class="o">.</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATIONS_500_COMPLETED</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">engine</span><span class="p">):</span>
    <span class="n">evaluator</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">validation_set</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">ignite.contrib.handlers.polyaxon_logger</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">plx_logger</span> <span class="o">=</span> <span class="n">PolyaxonLogger</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">global_step_transform</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">iteration</span>

<span class="c1"># Attach the logger to the evaluator on the validation dataset and log NLL, Accuracy metrics after</span>
<span class="c1"># every 500 iterations. Since evaluator engine does not have CustomPeriodicEvent attached to it, we</span>
<span class="c1"># provide a global_step_transform to return the trainer.state.iteration for the global_step, each time</span>
<span class="c1"># evaluator metrics are plotted on Polyaxon.</span>


<span class="n">plx_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">evaluator</span><span class="p">,</span>
                  <span class="n">log_handler</span><span class="o">=</span><span class="n">OutputHandler</span><span class="p">(</span><span class="n">tag</span><span class="o">=</span><span class="s2">&quot;validation&quot;</span><span class="p">,</span>
                                            <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;nll&quot;</span><span class="p">,</span> <span class="s2">&quot;accuracy&quot;</span><span class="p">],</span>
                                            <span class="n">global_step_transform</span><span class="o">=</span><span class="n">global_step_transform</span><span class="p">),</span>
                  <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">EPOCH_COMPLETED</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – common title for all produced plots. For example, ‘training’</li>
<li><strong>metric_names</strong> (<em>list of str</em><em>, </em><em>optional</em>) – list of metric names to plot or a string “all” to plot all available
metrics.</li>
<li><strong>output_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – output transform function to prepare <cite>engine.state.output</cite> as a number.
For example, <cite>output_transform = lambda output: output</cite>
This function can also return a dictionary, e.g <cite>{‘loss’: loss1, `another_loss</cite>: loss2}` to label the plot
with corresponding keys.</li>
<li><strong>another_engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.Engine" title="ignite.engine.Engine"><em>Engine</em></a>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">global_step_transform</span></code>). Another engine to use to provide the
value of event. Typically, user can provide
the trainer if this handler is attached to an evaluator and thus it logs proper trainer’s
epoch/iteration value.</li>
<li><strong>global_step_transform</strong> (<em>callable</em><em>, </em><em>optional</em>) – global step transform function to output a desired global step.
Input of the function is <cite>(engine, event_name)</cite>. Output of function should be an integer.
Default is None, global_step based on attached engine. If provided,
uses function output as global_step. To setup global step from another engine, please use
<a class="reference internal" href="#ignite.contrib.handlers.polyaxon_logger.global_step_from_engine" title="ignite.contrib.handlers.polyaxon_logger.global_step_from_engine"><code class="xref py py-meth docutils literal notranslate"><span class="pre">global_step_from_engine()</span></code></a>.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Example of <cite>global_step_transform</cite>:</p>
<div class="last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">global_step_transform</span><span class="p">(</span><span class="n">engine</span><span class="p">,</span> <span class="n">event_name</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">engine</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">get_event_attrib_value</span><span class="p">(</span><span class="n">event_name</span><span class="p">)</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="class">
<dt id="ignite.contrib.handlers.polyaxon_logger.OptimizerParamsHandler">
<em class="property">class </em><code class="descclassname">ignite.contrib.handlers.polyaxon_logger.</code><code class="descname">OptimizerParamsHandler</code><span class="sig-paren">(</span><em>optimizer</em>, <em>param_name='lr'</em>, <em>tag=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/contrib/handlers/polyaxon_logger.html#OptimizerParamsHandler"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.polyaxon_logger.OptimizerParamsHandler" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper handler to log optimizer parameters</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ignite.contrib.handlers.polyaxon_logger</span> <span class="kn">import</span> <span class="o">*</span>

<span class="c1"># Create a logger</span>
<span class="n">plx_logger</span> <span class="o">=</span> <span class="n">PolyaxonLogger</span><span class="p">()</span>

<span class="c1"># Attach the logger to the trainer to log optimizer&#39;s parameters, e.g. learning rate at each iteration</span>
<span class="n">plx_logger</span><span class="o">.</span><span class="n">attach</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span>
                  <span class="n">log_handler</span><span class="o">=</span><span class="n">OptimizerParamsHandler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">),</span>
                  <span class="n">event_name</span><span class="o">=</span><span class="n">Events</span><span class="o">.</span><span class="n">ITERATION_STARTED</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>optimizer</strong> (<em>torch.optim.Optimizer</em>) – torch optimizer which parameters to log</li>
<li><strong>param_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – parameter name</li>
<li><strong>tag</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a><em>, </em><em>optional</em>) – common title for all produced plots. For example, ‘generator’</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="ignite.contrib.handlers.polyaxon_logger.global_step_from_engine">
<code class="descclassname">ignite.contrib.handlers.polyaxon_logger.</code><code class="descname">global_step_from_engine</code><span class="sig-paren">(</span><em>engine</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/ignite/handlers.html#global_step_from_engine"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite.contrib.handlers.polyaxon_logger.global_step_from_engine" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper method to setup <cite>global_step_transform</cite> function using another engine.
This can be helpful for logging trainer epoch/iteration while output handler is attached to an evaluator.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><strong>engine</strong> (<a class="reference internal" href="../engine.html#ignite.engine.Engine" title="ignite.engine.Engine"><em>Engine</em></a>) – engine which state is used to provide the global step</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body">global step</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="more-on-parameter-scheduling">
<h2>More on parameter scheduling<a class="headerlink" href="#more-on-parameter-scheduling" title="Permalink to this headline">¶</a></h2>
<p>In this section there are visual examples of various parameter schedulings that can be achieved.</p>
<div class="section" id="example-with-ignite-contrib-handlers-cosineannealingscheduler">
<h3>Example with <code class="xref py py-class docutils literal notranslate"><span class="pre">ignite.contrib.handlers.CosineAnnealingScheduler</span></code><a class="headerlink" href="#example-with-ignite-contrib-handlers-cosineannealingscheduler" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">ignite.contrib.handlers</span> <span class="kn">import</span> <span class="n">CosineAnnealingScheduler</span>

<span class="n">lr_values_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">CosineAnnealingScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                                                            <span class="n">start_value</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">2e-2</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">20</span><span class="p">))</span>

<span class="n">lr_values_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">CosineAnnealingScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                                                                <span class="n">start_value</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">2e-2</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">cycle_mult</span><span class="o">=</span><span class="mf">1.3</span><span class="p">))</span>

<span class="n">lr_values_3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">CosineAnnealingScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                                                                <span class="n">start_value</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">2e-2</span><span class="p">,</span>
                                                                <span class="n">cycle_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">start_value_mult</span><span class="o">=</span><span class="mf">0.7</span><span class="p">))</span>

<span class="n">lr_values_4</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">CosineAnnealingScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                                                                <span class="n">start_value</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">2e-2</span><span class="p">,</span>
                                                                <span class="n">cycle_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">end_value_mult</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>


<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">141</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Cosine annealing&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">142</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Cosine annealing with cycle_mult=1.3&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">143</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Cosine annealing with start_value_mult=0.7&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_3</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_3</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">144</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Cosine annealing with end_value_mult=0.1&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_4</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_4</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">])</span>
</pre></div>
</div>
<img alt="../_images/cosine_annealing_example.png" src="../_images/cosine_annealing_example.png" />
</div>
<div class="section" id="example-with-ignite-contrib-handlers-linearcyclicalscheduler">
<h3>Example with <code class="xref py py-class docutils literal notranslate"><span class="pre">ignite.contrib.handlers.LinearCyclicalScheduler</span></code><a class="headerlink" href="#example-with-ignite-contrib-handlers-linearcyclicalscheduler" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">ignite.contrib.handlers</span> <span class="kn">import</span> <span class="n">LinearCyclicalScheduler</span>

<span class="n">lr_values_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">LinearCyclicalScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                                                                <span class="n">start_value</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">2e-2</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">20</span><span class="p">))</span>

<span class="n">lr_values_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">LinearCyclicalScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                                                                <span class="n">start_value</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">2e-2</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">cycle_mult</span><span class="o">=</span><span class="mf">1.3</span><span class="p">))</span>

<span class="n">lr_values_3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">LinearCyclicalScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                                                                <span class="n">start_value</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">2e-2</span><span class="p">,</span>
                                                                <span class="n">cycle_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">start_value_mult</span><span class="o">=</span><span class="mf">0.7</span><span class="p">))</span>

<span class="n">lr_values_4</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">LinearCyclicalScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span>
                                                                <span class="n">start_value</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">2e-2</span><span class="p">,</span>
                                                                <span class="n">cycle_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">end_value_mult</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>


<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">141</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Linear cyclical scheduler&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">142</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Linear cyclical scheduler with cycle_mult=1.3&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">143</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Linear cyclical scheduler with start_value_mult=0.7&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_3</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_3</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">144</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Linear cyclical scheduler with end_value_mult=0.1&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_4</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_4</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">])</span>
</pre></div>
</div>
<img alt="../_images/linear_cyclical_example.png" src="../_images/linear_cyclical_example.png" />
</div>
<div class="section" id="example-with-ignite-contrib-handlers-concatscheduler">
<h3>Example with <code class="xref py py-class docutils literal notranslate"><span class="pre">ignite.contrib.handlers.ConcatScheduler</span></code><a class="headerlink" href="#example-with-ignite-contrib-handlers-concatscheduler" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">ignite.contrib.handlers</span> <span class="kn">import</span> <span class="n">LinearCyclicalScheduler</span><span class="p">,</span> <span class="n">CosineAnnealingScheduler</span><span class="p">,</span> <span class="n">ConcatScheduler</span>

<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">t1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">([</span><span class="n">t1</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>


<span class="n">scheduler_1</span> <span class="o">=</span> <span class="n">LinearCyclicalScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">start_value</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">scheduler_2</span> <span class="o">=</span> <span class="n">CosineAnnealingScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">start_value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">durations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="p">]</span>

<span class="n">lr_values_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ConcatScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">schedulers</span><span class="o">=</span><span class="p">[</span><span class="n">scheduler_1</span><span class="p">,</span> <span class="n">scheduler_2</span><span class="p">],</span> <span class="n">durations</span><span class="o">=</span><span class="n">durations</span><span class="p">))</span>


<span class="n">t1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">([</span><span class="n">t1</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="n">scheduler_1</span> <span class="o">=</span> <span class="n">LinearCyclicalScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">start_value</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">scheduler_2</span> <span class="o">=</span> <span class="n">CosineAnnealingScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;momentum&quot;</span><span class="p">,</span> <span class="n">start_value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">durations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="p">]</span>

<span class="n">lr_values_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ConcatScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">schedulers</span><span class="o">=</span><span class="p">[</span><span class="n">scheduler_1</span><span class="p">,</span> <span class="n">scheduler_2</span><span class="p">],</span> <span class="n">durations</span><span class="o">=</span><span class="n">durations</span><span class="p">,</span>
                                                        <span class="n">param_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="s2">&quot;momentum&quot;</span><span class="p">]))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">131</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Concat scheduler of linear + cosine annealing&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">132</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Concat scheduler of linear LR scheduler</span><span class="se">\n</span><span class="s2"> and cosine annealing on momentum&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">133</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Concat scheduler of linear LR scheduler</span><span class="se">\n</span><span class="s2"> and cosine annealing on momentum&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;momentum&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/concat_example.png" src="../_images/concat_example.png" />
<div class="section" id="piecewise-linear-scheduler">
<h4>Piecewise linear scheduler<a class="headerlink" href="#piecewise-linear-scheduler" title="Permalink to this headline">¶</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">ignite.contrib.handlers</span> <span class="kn">import</span> <span class="n">LinearCyclicalScheduler</span><span class="p">,</span> <span class="n">ConcatScheduler</span>

<span class="n">scheduler_1</span> <span class="o">=</span> <span class="n">LinearCyclicalScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">start_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">scheduler_2</span> <span class="o">=</span> <span class="n">LinearCyclicalScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">start_value</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
<span class="n">durations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="p">]</span>

<span class="n">lr_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ConcatScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">schedulers</span><span class="o">=</span><span class="p">[</span><span class="n">scheduler_1</span><span class="p">,</span> <span class="n">scheduler_2</span><span class="p">],</span> <span class="n">durations</span><span class="o">=</span><span class="n">durations</span><span class="p">))</span>


<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Piecewise linear scheduler&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/piecewise_linear.png" src="../_images/piecewise_linear.png" />
</div>
</div>
<div class="section" id="example-with-ignite-contrib-handlers-lrscheduler">
<h3>Example with <code class="xref py py-class docutils literal notranslate"><span class="pre">ignite.contrib.handlers.LRScheduler</span></code><a class="headerlink" href="#example-with-ignite-contrib-handlers-lrscheduler" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">ignite.contrib.handlers</span> <span class="kn">import</span> <span class="n">LRScheduler</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.optim.lr_scheduler</span> <span class="kn">import</span> <span class="n">ExponentialLR</span><span class="p">,</span> <span class="n">StepLR</span><span class="p">,</span> <span class="n">CosineAnnealingLR</span>

<span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">([</span><span class="n">tensor</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="n">lr_scheduler_1</span> <span class="o">=</span> <span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.77</span><span class="p">)</span>
<span class="n">lr_scheduler_2</span> <span class="o">=</span> <span class="n">ExponentialLR</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.98</span><span class="p">)</span>
<span class="n">lr_scheduler_3</span> <span class="o">=</span> <span class="n">CosineAnnealingLR</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">T_max</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">eta_min</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="n">lr_values_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">LRScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="o">=</span><span class="n">lr_scheduler_1</span><span class="p">))</span>
<span class="n">lr_values_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">LRScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="o">=</span><span class="n">lr_scheduler_2</span><span class="p">))</span>
<span class="n">lr_values_3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">LRScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="o">=</span><span class="n">lr_scheduler_3</span><span class="p">))</span>


<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">131</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Torch LR scheduler wrapping StepLR&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">132</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Torch LR scheduler wrapping ExponentialLR&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">133</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Torch LR scheduler wrapping CosineAnnealingLR&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_3</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_3</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/lr_scheduler.png" src="../_images/lr_scheduler.png" />
<div class="section" id="concatenate-with-torch-schedulers">
<h4>Concatenate with torch schedulers<a class="headerlink" href="#concatenate-with-torch-schedulers" title="Permalink to this headline">¶</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">ignite.contrib.handlers</span> <span class="kn">import</span> <span class="n">LRScheduler</span><span class="p">,</span> <span class="n">ConcatScheduler</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.optim.lr_scheduler</span> <span class="kn">import</span> <span class="n">ExponentialLR</span><span class="p">,</span> <span class="n">StepLR</span>

<span class="n">t1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">([</span><span class="n">t1</span><span class="p">],</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="n">scheduler_1</span> <span class="o">=</span> <span class="n">LinearCyclicalScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">start_value</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">ExponentialLR</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">scheduler_2</span> <span class="o">=</span> <span class="n">LRScheduler</span><span class="p">(</span><span class="n">lr_scheduler</span><span class="o">=</span><span class="n">lr_scheduler</span><span class="p">)</span>
<span class="n">durations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="p">]</span>
<span class="n">lr_values_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ConcatScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">schedulers</span><span class="o">=</span><span class="p">[</span><span class="n">scheduler_1</span><span class="p">,</span> <span class="n">scheduler_2</span><span class="p">],</span> <span class="n">durations</span><span class="o">=</span><span class="n">durations</span><span class="p">))</span>


<span class="n">scheduler_1</span> <span class="o">=</span> <span class="n">LinearCyclicalScheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s2">&quot;lr&quot;</span><span class="p">,</span> <span class="n">start_value</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">end_value</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">cycle_size</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">scheduler_2</span> <span class="o">=</span> <span class="n">LRScheduler</span><span class="p">(</span><span class="n">lr_scheduler</span><span class="o">=</span><span class="n">lr_scheduler</span><span class="p">)</span>
<span class="n">durations</span> <span class="o">=</span> <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="p">]</span>
<span class="n">lr_values_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ConcatScheduler</span><span class="o">.</span><span class="n">simulate_values</span><span class="p">(</span><span class="n">num_events</span><span class="o">=</span><span class="mi">75</span><span class="p">,</span> <span class="n">schedulers</span><span class="o">=</span><span class="p">[</span><span class="n">scheduler_1</span><span class="p">,</span> <span class="n">scheduler_2</span><span class="p">],</span> <span class="n">durations</span><span class="o">=</span><span class="n">durations</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Concat scheduler of linear + ExponentialLR&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Concat scheduler of linear + StepLR&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lr_values_2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;learning rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;events&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;values&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/concat_linear_exp_step_lr.png" src="../_images/concat_linear_exp_step_lr.png" />
</div>
</div>
</div>
</div>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
      
        <a href="metrics.html" class="btn btn-neutral" title="ignite.contrib.metrics" accesskey="p" rel="prev"><img src="../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Torch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">ignite.contrib.handlers</a><ul>
<li><a class="reference internal" href="#module-ignite.contrib.handlers.custom_events">custom_events</a></li>
<li><a class="reference internal" href="#module-ignite.contrib.handlers.param_scheduler">param_scheduler</a></li>
<li><a class="reference internal" href="#tensorboard-logger">tensorboard_logger</a></li>
<li><a class="reference internal" href="#visdom-logger">visdom_logger</a></li>
<li><a class="reference internal" href="#module-ignite.contrib.handlers.mlflow_logger">mlflow_logger</a></li>
<li><a class="reference internal" href="#module-ignite.contrib.handlers.tqdm_logger">tqdm_logger</a></li>
<li><a class="reference internal" href="#module-ignite.contrib.handlers.polyaxon_logger">polyaxon_logger</a></li>
<li><a class="reference internal" href="#more-on-parameter-scheduling">More on parameter scheduling</a><ul>
<li><a class="reference internal" href="#example-with-ignite-contrib-handlers-cosineannealingscheduler">Example with <code class="docutils literal notranslate"><span class="pre">ignite.contrib.handlers.CosineAnnealingScheduler</span></code></a></li>
<li><a class="reference internal" href="#example-with-ignite-contrib-handlers-linearcyclicalscheduler">Example with <code class="docutils literal notranslate"><span class="pre">ignite.contrib.handlers.LinearCyclicalScheduler</span></code></a></li>
<li><a class="reference internal" href="#example-with-ignite-contrib-handlers-concatscheduler">Example with <code class="docutils literal notranslate"><span class="pre">ignite.contrib.handlers.ConcatScheduler</span></code></a><ul>
<li><a class="reference internal" href="#piecewise-linear-scheduler">Piecewise linear scheduler</a></li>
</ul>
</li>
<li><a class="reference internal" href="#example-with-ignite-contrib-handlers-lrscheduler">Example with <code class="docutils literal notranslate"><span class="pre">ignite.contrib.handlers.LRScheduler</span></code></a><ul>
<li><a class="reference internal" href="#concatenate-with-torch-schedulers">Concatenate with torch schedulers</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script type="text/javascript" src="../_static/jquery.js"></script>
         <script type="text/javascript" src="../_static/underscore.js"></script>
         <script type="text/javascript" src="../_static/doctools.js"></script>
         <script type="text/javascript" src="../_static/language_data.js"></script>
         <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

  <!-- Begin Footer -->

  <!-- commented out for Ignite -->
  <!--

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/ignite/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/ignite/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/ignite/">PyTorch</a></li>
            <li><a href="https://pytorch.org/ignite/get-started">Get Started</a></li>
            <li><a href="">Features</a></li>
            <li><a href="">Ecosystem</a></li>
            <li><a href="">Blog</a></li>
            <li><a href="">Resources</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="">Support</a></li>
            <li><a href="">Tutorials</a></li>
            <li><a href="https://pytorch.org/ignite/index.html">Docs</a></li>
            <li><a href="" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/ignite/issues" target="_blank">Github Issues</a></li>
            <li><a href="" target="_blank">Slack</a></li>
            <li><a href="https://github.com/pytorch/ignite/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Follow Us</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!~~ real people should not fill this in and expect good things - do not remove this or risk form bot signups ~~>

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="" target="_blank" class="facebook"></a>
            <a href="" target="_blank" class="twitter"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  -->
  <!-- end of commented out for Ignite -->

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->
  <!--
  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/ignite/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="#">Get Started</a>
          </li>

          <li>
            <a href="#">Features</a>
          </li>

          <li>
            <a href="#">Ecosystem</a>
          </li>

          <li>
            <a href="">Blog</a>
          </li>

          <li>
            <a href="">Tutorials</a>
          </li>

          <li>
            <a href="https://pytorch.org/ignite/index.html">Docs</a>
          </li>

          <li>
            <a href="">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/ignite">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>
  -->
  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>